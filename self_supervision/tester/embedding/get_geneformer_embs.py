import os
from pathlib import Path
import pickle
from geneformer import TranscriptomeTokenizer
from geneformer import EmbExtractor
import numpy as np
import argparse
from self_supervision.paths import DATA_DIR


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument("--split", type=str)
    args = parser.parse_args()
    split = args.split

    print("split: ", split)


    split_directory = os.path.join(DATA_DIR, "geneformer_embs", split)
    dataset_path = (Path(split_directory) / split).with_suffix(".dataset")


    tk = TranscriptomeTokenizer({"cell_type": "cell_type"}, nproc=16)

    if not os.path.exists(os.path.join(split_directory, "tokenized_cells.pickle")):
        # tokenize the data
        print("Tokenizing data...")
        tokenized_cells, cell_metadata = tk.tokenize_data(
            DATA_DIR,
            os.path.join(DATA_DIR, "geneformer_embs"),
            split,
            split=split,
            file_format="h5ad",
        )

        # save the tokenized cells and cell metadata
        with open(os.path.join(split_directory, "tokenized_cells.pickle"), "wb") as f:
            pickle.dump(tokenized_cells, f)
        with open(os.path.join(split_directory, "cell_metadata.pickle"), "wb") as f:
            pickle.dump(cell_metadata, f)
    else:
        print("Loading tokenized cells and cell metadata...")
        # read tokenized_cells, cell_metadata from pickle files
        import pickle

        with open(os.path.join(split_directory, "tokenized_cells.pickle"), "rb") as f:
            tokenized_cells = pickle.load(f)
        with open(os.path.join(split_directory, "cell_metadata.pickle"), "rb") as f:
            cell_metadata = pickle.load(f)

    print("tokenized_cells: ", len(tokenized_cells))
    print("cell_metadata: ", len(cell_metadata["cell_type"]))

    if not os.path.exists(dataset_path):
        print("Creating dataset at {}...".format(dataset_path))
        tokenized_dataset = tk.create_dataset(
            tokenized_cells, cell_metadata, use_generator=True
        )
        tokenized_dataset.save_to_disk(dataset_path)


    print("Extracting embeddings...")
    # initiate EmbExtractor
    embex = EmbExtractor(
        model_type="Pretrained",
        num_classes=0,
        filter_data=None,
        max_ncells=None,
        emb_layer=-1,
        emb_label=None,
        labels_to_plot=None,
        forward_batch_size=32,
        nproc=16,
    )

    # extracts embedding from input data
    # input data is tokenized rank value encodings generated by Geneformer tokenizer (see tokenizing_scRNAseq_data.ipynb)
    # example dataset: https://huggingface.co/datasets/ctheodoris/Genecorpus-30M/tree/main/example_input_files/cell_classification/disease_classification/human_dcm_hcm_nf.dataset
    embs = embex.extract_embs(
        os.path.join(DATA_DIR, "Geneformer", "geneformer-12L-30M"),
        dataset_path,
        split_directory,
        "embeddings",
    )


    print("Saving embeddings...")
    np.save(os.path.join(split_directory, "embs.npy"), embs.values)
    np.save(
        os.path.join(split_directory, "cell_type.npy"), np.array(cell_metadata["cell_type"])
    )
