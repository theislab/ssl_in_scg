{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2e347a-c7cb-4e6a-b3fb-da111a82f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from self_supervision.paths import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3b7cd3-799b-436b-ade3-062f3bbb75e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_matrix_and_obs(ddf):\n",
    "    x = (\n",
    "        ddf['X']\n",
    "        .map_partitions(\n",
    "            lambda xx: pd.DataFrame(np.vstack(xx.tolist())),\n",
    "            meta={col: 'f4' for col in range(19331)}\n",
    "        )\n",
    "        .to_dask_array(lengths=[1024] * ddf.npartitions)\n",
    "    )\n",
    "    obs = ddf[['cell_type', 'tech_sample']].compute()\n",
    "\n",
    "    return x, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196c09db-c7c0-4f69-8426-eafabbc1b612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  (15240192, 19331)\n"
     ]
    }
   ],
   "source": [
    "STORE_DIR = os.path.join(DATA_DIR, 'merlin_cxg_2023_05_15_sf-log1p')\n",
    "\n",
    "ddf_train = dd.read_parquet(join(STORE_DIR, 'train'), split_row_groups=True)\n",
    "x_train, obs_train = get_count_matrix_and_obs(ddf_train)\n",
    "print('Train data: ', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31ec45c3-5934-4302-9b29-674aab15ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampled data:  (1524019, 19331)\n"
     ]
    }
   ],
   "source": [
    "# randomly subsample train data\n",
    "perc = 10\n",
    "total_rows = x_train.shape[0]\n",
    "rows_to_select = int(total_rows * (perc / 100))\n",
    "random_indices = np.random.choice(total_rows, size=rows_to_select, replace=False)\n",
    "x_train_sub = x_train[random_indices, ]\n",
    "\n",
    "print('Subsampled data: ', x_train_sub.shape)\n",
    "\n",
    "# Create a boolean mask to select the desired rows\n",
    "mask = np.zeros(len(obs_train), dtype=bool)\n",
    "mask[random_indices] = True\n",
    "obs_train_sub = obs_train.iloc[mask]\n",
    "\n",
    "adata = anndata.AnnData(X=x_train_sub, obs=obs_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db88414-5289-418a-a49a-5f7a1c11050c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1524019 × 19331\n",
       "    obs: 'cell_type', 'tech_sample'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa9762-07b2-4748-9912-ebb8d31c4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hvgs in [2000, 1000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]:\n",
    "    \n",
    "\n",
    "    out = sc.pp.highly_variable_genes(adata, n_top_genes=hvgs, inplace=False)\n",
    "\n",
    "    hvg_indices = list(out.loc[out['highly_variable']].index)\n",
    "\n",
    "    with open('hvg_' + str(hvgs) + '_indices.pickle', 'wb') as f:\n",
    "        pickle.dump(list(hvg_indices), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c45f7a9-cfbc-4854-bdc8-9eeb23ed0275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pickle file contains a list of 1000 indices.\n",
      "Indices range from 15 to 19307\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Step 1: Load the pickle file\n",
    "with open(DATA_DIR + 'hvg_indices1000.pickle', \"rb\") as f:\n",
    "    hvg_indices = pickle.load(f)\n",
    "\n",
    "# Step 2: Type and Length Check\n",
    "if isinstance(hvg_indices, list) and len(hvg_indices) == 1000:\n",
    "    print(\"The pickle file contains a list of 1000 indices.\")\n",
    "else:\n",
    "    print(f\"Unexpected content: Type-{type(hvg_indices)}, Length-{len(hvg_indices)}\")\n",
    "\n",
    "# Step 3: Index Range (optional)\n",
    "if all(isinstance(index, int) for index in hvg_indices):\n",
    "    print(f\"Indices range from {min(hvg_indices)} to {max(hvg_indices)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:celldreamer]",
   "language": "python",
   "name": "celldreamer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
