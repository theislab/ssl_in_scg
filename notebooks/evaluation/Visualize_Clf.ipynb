{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6566e4-80ef-44c5-abbe-c93a13a6cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae353b4-227a-4515-8aee-4543a5c09c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce184040-bed6-4865-b944-914ee40e1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from self_supervision.paths import DATA_DIR, TRAINING_FOLDER, RESULTS_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c92a8-d084-475a-b407-74db0c423267",
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE_DIR = os.path.join(DATA_DIR, 'merlin_cxg_2023_05_15_sf-log1p')\n",
    "HVG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab556c63-9fbf-45b9-9993-a1c46dc80aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust size as needed\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}  # Adjust font size for tick labels\n",
    "\n",
    "# Set the colorblind friendly palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# Get the list of colors in the palette\n",
    "palette_colors = sns.color_palette(\"colorblind\")\n",
    "\n",
    "# Access the colors\n",
    "color_supervised = palette_colors[0]  # First color\n",
    "color_ssl = palette_colors[1]  # Second color\n",
    "color_zeroshot = palette_colors[2]  # Third color\n",
    "color_baseline = palette_colors[3]  # Forth color, ([3] looks similar to [0])\n",
    "color_else1 = palette_colors[5]\n",
    "color_else2 = palette_colors[6]\n",
    "color_else3 = palette_colors[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c39c7-c25b-43b2-94fd-8eb8cdf86e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the model types to specific colors\n",
    "color_dict = {\n",
    "    'Zero-Shot\\nRandom Mask': color_zeroshot,\n",
    "    'Zero-Shot:\\nRandom Mask': color_zeroshot,\n",
    "    'Zero-Shot\\nGP Mask': color_zeroshot,\n",
    "    'Zero-Shot\\nGP to TF': color_zeroshot,\n",
    "    'Zero-Shot\\nGP to GP': color_zeroshot,\n",
    "    'Zero-Shot\\nBYOL': color_zeroshot,\n",
    "    'Zero-Shot\\nBarlow Twins': color_zeroshot,\n",
    "    'Supervised': color_supervised,\n",
    "    'PCA': palette_colors[3],\n",
    "    'Random': palette_colors[3],\n",
    "    'Self-Supervised\\nRandom Mask': color_ssl,\n",
    "    'Self-Supervised\\nGP Mask': color_ssl,\n",
    "    'Self-Supervised\\nGP to TF': color_ssl,\n",
    "    'Self-Supervised\\nGP to GP': color_ssl,\n",
    "    'Self-Supervised\\nBYOL': color_ssl,\n",
    "    'Self-Supervised\\nBarlow Twins': color_ssl\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c15e86-a07e-4476-957d-9a6bf89c6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5082c685-c446-4e48-a806-f089bd295224",
   "metadata": {},
   "source": [
    "# Figure 1\n",
    "Compare performance on hold out test set on CellNet\n",
    "\n",
    "kNN classification to include PCA, scVI, Only Pretrained, Supervised, and Self-Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d17620-99c7-4a89-aa21-9dde9ecd5e1a",
   "metadata": {},
   "source": [
    "1) Full Transcriptome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3692dd1e-ee5b-444e-8fd6-85fba4469175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_CellNet_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop duplicates\n",
    "df_unique = df.drop_duplicates()\n",
    "df_unique.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94309ba7-76ce-4af3-bff2-198173b0aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_select = ['CN_MLP_50prun2_Only Pretrained',  # Best Run \n",
    "                    'CN_MLP_gene_program_C8_25p_Only Pretrained', \n",
    "                    'CN_MLP_gp_to_tf_Only Pretrained', \n",
    "                    'CN_MLP_single_gene_program_Only Pretrained',\n",
    "                    'MLP_BYOL_Gaussian_0_001_v4_Only Pretrained',\n",
    "                    'GeneFormer',\n",
    "                    'No_SSL_run1_No SSL',  # Best Run\n",
    "                    'PCA',\n",
    "                    'Random',\n",
    "                    'SSL_CN_MLP_50prun4_SSL',  # Best Run\n",
    "                    'SSL_CN_MLP_gene_program_C8_25prun0_SSL',  # Best Run\n",
    "                    'SSL_CN_MLP_gp_to_tfrun0_SSL',\n",
    "                    'SSL_CN_MLP_single_gene_programrun0_SSL',\n",
    "                    'SSL_MLP_BYOL_Gaussian_0_001run0_SSL',\n",
    "                    'SSL_contrastive_MLP_bt_Gaussian_0_01run0_SSL',\n",
    "                    '_Only Pretrained',\n",
    "                   ]\n",
    "\n",
    "df_subset = df_unique[df_unique['Unnamed: 0'].isin(models_to_select)]\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24177d8f-8c4e-4c9e-89d8-b466900842a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_names = {\n",
    "    'CN_MLP_50prun2_Only Pretrained': 'Zero-Shot\\nRandom Mask',\n",
    "    'CN_MLP_gene_program_C8_25p_Only Pretrained': 'Zero-Shot\\nGP Mask',\n",
    "    'CN_MLP_gp_to_tf_Only Pretrained': 'Zero-Shot\\nGP to TF',\n",
    "    'CN_MLP_single_gene_program_Only Pretrained': 'Zero-Shot\\nGP to GP',\n",
    "    'MLP_BYOL_Gaussian_0_001_v4_Only Pretrained': 'Zero-Shot\\nBYOL',\n",
    "    '_Only Pretrained': 'Zero-Shot\\nBarlow Twins',\n",
    "    'No_SSL_run1_No SSL': 'Supervised',\n",
    "    'Random': 'Random',\n",
    "    'PCA': 'PCA',\n",
    "    'GeneFormer': 'GeneFormer',\n",
    "    'SSL_CN_MLP_50prun4_SSL': 'Self-Supervised\\nRandom Mask',\n",
    "    'SSL_CN_MLP_gene_program_C8_25prun0_SSL': 'Self-Supervised\\nGP Mask',\n",
    "    'SSL_CN_MLP_gp_to_tfrun0_SSL': 'Self-Supervised\\nGP to TF',\n",
    "    'SSL_CN_MLP_single_gene_programrun0_SSL': 'Self-Supervised\\nGP to GP',\n",
    "    'SSL_MLP_BYOL_Gaussian_0_001run0_SSL': 'Self-Supervised\\nBYOL',\n",
    "    'SSL_contrastive_MLP_bt_Gaussian_0_01run0_SSL': 'Self-Supervised\\nBarlow Twins',\n",
    "}\n",
    "\n",
    "df_subset['Unnamed: 0'] = df_subset['Unnamed: 0'].apply(lambda x: custom_model_names.get(x, x))\n",
    "df_subset = df_subset.drop_duplicates(subset='Unnamed: 0', keep='first')\n",
    "\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40611db6-82a3-4a17-80b7-5b35dc9623cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map the model types to specific colors\n",
    "color_dict = {\n",
    "    'Zero-Shot\\nRandom Mask': color_zeroshot,\n",
    "    'Zero-Shot:\\nRandom Mask': color_zeroshot,\n",
    "    'Zero-Shot\\nGP Mask': color_zeroshot,\n",
    "    'Zero-Shot\\nGP to TF': color_zeroshot,\n",
    "    'Zero-Shot\\nGP to GP': color_zeroshot,\n",
    "    'Zero-Shot\\nBYOL': color_zeroshot,\n",
    "    'Zero-Shot\\nBarlow Twins': color_zeroshot,\n",
    "    'Supervised': color_supervised,\n",
    "    'PCA': palette_colors[3],\n",
    "    'GeneFormer': palette_colors[3],\n",
    "    'Random': palette_colors[3],\n",
    "    'Self-Supervised\\nRandom Mask': color_ssl,\n",
    "    'Self-Supervised\\nGP Mask': color_ssl,\n",
    "    'Self-Supervised\\nGP to TF': color_ssl,\n",
    "    'Self-Supervised\\nGP to GP': color_ssl,\n",
    "    'Self-Supervised\\nBYOL': color_ssl,\n",
    "    'Self-Supervised\\nBarlow Twins': color_ssl\n",
    "}\n",
    "\n",
    "tick_font_size = 5  # For tick labels\n",
    "\n",
    "df_subset['Color'] = df_subset['Unnamed: 0'].map(color_dict)\n",
    "assert not df_subset['Color'].isnull().any(), \"Some model types don't have a color assigned in the color_dict.\"\n",
    "\n",
    "# Sort the dataframe by 'f1-score: accuracy' for the barplot\n",
    "df_subset_sorted_micro = df_subset.sort_values('f1-score: accuracy')\n",
    "\n",
    "# Sort the dataframe by 'f1-score: macro avg' for the barplot\n",
    "df_subset_sorted_macro = df_subset.sort_values('f1-score: macro avg')\n",
    "\n",
    "\n",
    "# Adjusted function to annotate bars\n",
    "def annotate_bars(ax, data, score_column):\n",
    "    max_height = data[score_column].max()\n",
    "    for p in ax.patches:\n",
    "        annotation = f\"{p.get_height():.2f}\"\n",
    "        # weight = 'bold' if p.get_height() == max_height else 'normal'\n",
    "        weight='normal'\n",
    "        ax.annotate(annotation, (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=font['size'], weight=weight)\n",
    "\n",
    "# Micro F1 Score plot\n",
    "plt.figure(figsize=(3.5, 1.75))\n",
    "ax1 = sns.barplot(x='Unnamed: 0', y='f1-score: accuracy', data=df_subset_sorted_micro,\n",
    "                  palette=df_subset_sorted_micro['Color'].tolist())\n",
    "ax1.set_ylim(0.0, 1.0)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right', fontsize=tick_font_size)\n",
    "ax1.set_yticklabels([])\n",
    "ax1.set_xlabel('Model', fontsize=font['size'])\n",
    "ax1.set_ylabel('Micro F1 Score', fontsize=font['size'])\n",
    "annotate_bars(ax1, df_subset_sorted_micro, 'f1-score: accuracy')\n",
    "plt.tight_layout()\n",
    "ax1.set_title('Comparison of Models Based on Micro F1 Score', fontsize=font['size'])\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Model_Comparison_Micro_F1_incl_GeneFormer.svg\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Macro F1 Score plot\n",
    "plt.figure(figsize=(3.5, 1.75))\n",
    "ax2 = sns.barplot(x='Unnamed: 0', y='f1-score: macro avg', data=df_subset_sorted_macro,\n",
    "                  palette=df_subset_sorted_macro['Color'].tolist())\n",
    "ax2.set_ylim(0.0, 1.0)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right', fontsize=tick_font_size)\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_xlabel('Model', fontsize=font['size'])\n",
    "ax2.set_ylabel('Macro F1 Score', fontsize=font['size'])\n",
    "ax2.set_title('Comparison of Models Based on Macro F1 Score', fontsize=font['size'])\n",
    "annotate_bars(ax2, df_subset_sorted_macro, 'f1-score: macro avg')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Model_Comparison_Macro_F1_incl_GeneFormer.svg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd445af-3700-4036-8ac7-42ebadb09558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the style for the plots\n",
    "sns.set_theme()\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties for titles and labels\n",
    "font = {'family': 'sans-serif', 'size': 5}  # This will be for titles and labels\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}  # For tick labels\n",
    "\n",
    "def annotate_bars(ax):\n",
    "    for i, p in enumerate(ax.patches):\n",
    "        vertical_offset = p.get_height() * 0.01  # Small vertical offset\n",
    "        font_weight = 'bold' if i == len(ax.patches) - 1 else 'normal'\n",
    "        ax.annotate(f\"{p.get_height():.2f}\",\n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height() + vertical_offset),\n",
    "                    ha='center', va='baseline',\n",
    "                    **font, weight=font_weight)  # Using the font dictionary here\n",
    "\n",
    "# Plot for Micro F1 Score\n",
    "plt.figure(figsize=(5, 2))\n",
    "ax1 = sns.barplot(x='Unnamed: 0', y='f1-score: accuracy', data=df_subset.sort_values('f1-score: accuracy'))\n",
    "ax1.set_ylim(0.0, 1.0)\n",
    "\n",
    "# Set the font for the tick labels and rotate them for better visibility\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right', **tick_font)\n",
    "plt.setp(ax1.get_xticklabels(), va=\"top\", ha=\"right\")  # Adjust the vertical alignment\n",
    "\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax1.set_xlabel('Model', fontdict=font)\n",
    "ax1.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax1.set_title('Comparison of Models Based on Micro F1 Score', fontdict=font)\n",
    "\n",
    "# Annotate bars\n",
    "annotate_bars(ax1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Model_Comparison_Micro_F1.svg\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot for Macro F1 Score\n",
    "plt.figure(figsize=(5, 2))\n",
    "ax2 = sns.barplot(x='Unnamed: 0', y='f1-score: macro avg', data=df_subset.sort_values('f1-score: macro avg'))\n",
    "ax2.set_ylim(0.0, 1.0)\n",
    "\n",
    "# Set the font for the tick labels and rotate them for better visibility\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right', **tick_font)\n",
    "plt.setp(ax2.get_xticklabels(), va=\"top\", ha=\"right\")  # Adjust the vertical alignment\n",
    "\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax2.set_xlabel('Model', fontdict=font)\n",
    "ax2.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax2.set_title('Comparison of Models Based on Macro F1 Score', fontdict=font)\n",
    "\n",
    "# Annotate bars\n",
    "annotate_bars(ax2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Model_Comparison_Macro_F1.svg\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78afa6d-f9ef-4198-8e03-02ef7d3e6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_CellNet_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e079e8f-5486-438a-bf53-8ee1fe427597",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_select = ['CN_MLP_50p_Only Pretrained', \n",
    "                    'CN_MLP_50prun1_Only Pretrained', \n",
    "                    'CN_MLP_50prun2_Only Pretrained', \n",
    "                    'CN_MLP_50prun3_Only Pretrained',\n",
    "                    'CN_MLP_50prun4_Only Pretrained',\n",
    "                    'No_SSL_run0_No SSL',\n",
    "                    'No_SSL_run1_No SSL',\n",
    "                    'No_SSL_run2_No SSL',\n",
    "                    'No_SSL_run3_No SSL',\n",
    "                    'No_SSL_run4_No SSL',\n",
    "                    'SSL_CN_MLP_50prun0_SSL',\n",
    "                    'SSL_CN_MLP_50prun1_SSL',\n",
    "                    'SSL_CN_MLP_50prun2_SSL',\n",
    "                    'SSL_CN_MLP_50prun3_SSL',\n",
    "                    'SSL_CN_MLP_50prun4_SSL',\n",
    "                   ]\n",
    "\n",
    "df_subset = df[df['Unnamed: 0'].isin(models_to_select)]\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589202f-fa4b-4e14-a498-5750aed24d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the model name from the 'Unnamed: 0' column (assuming it's the first part of the string before the '_')\n",
    "df_subset['Model'] = df_subset['Unnamed: 0'].str.extract(r'(.*?)_run')\n",
    "\n",
    "# Ensure that the f1-score columns are of float type\n",
    "df_subset['f1-score: accuracy'] = df_subset['f1-score: accuracy'].astype(float)\n",
    "df_subset['f1-score: macro avg'] = df_subset['f1-score: macro avg'].astype(float)\n",
    "\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9f5ca-2177-442b-abbe-ccf4b0fdb94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_model_type(row):\n",
    "    if 'SSL_CN_MLP' in row['Unnamed: 0']:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'CN_MLP' in row['Unnamed: 0']:\n",
    "        return 'Zero-Shot\\nRandom Mask'\n",
    "    elif 'No_SSL' in row['Unnamed: 0']:\n",
    "        return 'Supervised'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df_subset['Model'] = df_subset.apply(extract_model_type, axis=1)\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33becd16-e163-4d40-bc88-2dd5d3a4afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the style for the plots\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties for titles and labels\n",
    "font = {'family': 'sans-serif', 'size': 5}\n",
    "tick_font = {'size': 5}\n",
    "\n",
    "# Debugging: Print median values before plotting\n",
    "# print(df_subset.groupby('Model')['f1-score: macro avg'].median())\n",
    "\n",
    "# Plot for Macro F1 Score with individual points\n",
    "plt.figure(figsize=(2.3, 1.3))\n",
    "ax = sns.boxplot(x='Model', y='f1-score: macro avg', data=df_subset, linewidth=0.5)\n",
    "sns.swarmplot(x='Model', y='f1-score: macro avg', data=df_subset, color='black', size=1)\n",
    "\n",
    "# Set the font for the tick labels and axis labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font)\n",
    "# ax.set_yticklabels([f\"{x:.2f}\" for x in ax.get_yticks()], **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Model', **font)\n",
    "ax.set_ylabel('Macro F1 Score', **font)\n",
    "ax.set_title('Classification Performance on scTab Test Set', **font)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef6a7e5-d96a-4826-afd4-a1f227ce8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the 'Model' column to colors\n",
    "df_subset['Color'] = df_subset['Model'].map(color_dict)\n",
    "# Function to categorize models\n",
    "def extract_model_type(row):\n",
    "    if 'Only Pretrained' in row['Unnamed: 0']:\n",
    "        return 'Zero-Shot:\\nRandom Mask'\n",
    "    elif 'No SSL' in row['Unnamed: 0']:\n",
    "        return 'Supervised'\n",
    "    elif 'SSL_CN' in row['Unnamed: 0']:\n",
    "        return 'Self-Supervised:\\nRandom Mask'\n",
    "    else:\n",
    "        return 'Error'\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df_subset['Model'] = df_subset.apply(extract_model_type, axis=1)\n",
    "\n",
    "# Ensure that the f1-score columns are of float type\n",
    "df_subset['f1-score: accuracy'] = df_subset['f1-score: accuracy'].astype(float)\n",
    "df_subset['f1-score: macro avg'] = df_subset['f1-score: macro avg'].astype(float)\n",
    "\n",
    "# Define font properties for titles and labels\n",
    "font = {'family': 'sans-serif', 'size': 5}\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}\n",
    "\n",
    "# Plot for Micro F1 Score\n",
    "plt.figure(figsize=(2.3, 1.8))\n",
    "ax1 = sns.boxplot(x='Model', y='f1-score: accuracy', data=df_subset, linewidth=0.5, palette=df_subset['Color'].unique().tolist())\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), **tick_font)\n",
    "ax1.set_yticklabels([])\n",
    "ax1.set_xlabel('Model', fontdict=font)\n",
    "ax1.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax1.set_title('Classification Performance on scTab Test Set', fontdict=font)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Model_Comparison_Micro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n",
    "\n",
    "# Plot for Macro F1 Score\n",
    "plt.figure(figsize=(2.3, 1.8))\n",
    "ax2 = sns.boxplot(x='Model', y='f1-score: macro avg', data=df_subset, linewidth=0.5, palette=df_subset['Color'].unique().tolist())\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), **tick_font)\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_xlabel('Model', fontdict=font)\n",
    "ax2.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax2.set_title('Classification Performance on scTab Test Set', fontdict=font)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Model_Comparison_Macro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0defe4d-38c4-4f44-9877-e597f058c40c",
   "metadata": {},
   "source": [
    "# Figure 2\n",
    "\n",
    "OOD task, where supervised learning may come to its limits\n",
    "\n",
    "Novel, unseen dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7debe3-e758-496e-8925-15331ed6492f",
   "metadata": {},
   "source": [
    "**Dissection: Tail of Hippocampus (HiT) - Caudal Hippocampus - CA4-DGC**\n",
    "\n",
    "- 56,367 cells\n",
    "- 10x 3' v3\n",
    "- hippocampal formation\n",
    "- astrocyte (3761), central nervous system macrophage (1782), endothelial cell (174), ependymal cell (111), ~~fibroblast (86)~~, leukocyte (36), neuron (36588), oligodendrocyte (11875), oligodendrocyte precursor cell (1896), pericyte (39), vascular associated smooth muscle cell (19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da62f82-e0dd-4964-b1d5-e57aeda58ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_OOD_HiT_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826a4fd-3630-491d-b0ef-bfc374e64a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your dataframe after filtering to only include the desired runs\n",
    "\n",
    "def extract_model_type(row):\n",
    "    if 'Only Pretrained' in row['Unnamed: 0']:\n",
    "        return 'Zero-Shot\\nRandom Mask'\n",
    "    elif 'No SSL' in row['Unnamed: 0']:\n",
    "        return 'Supervised'\n",
    "    elif 'SSL_CN' in row['Unnamed: 0']:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'Random' in row['Unnamed: 0']:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return 'Error'\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['Model'] = df.apply(extract_model_type, axis=1)\n",
    "\n",
    "# Filter outliers\n",
    "df = df[~df['Unnamed: 0'].isin(['No_SSL_run0_No SSL', 'No_SSL_run4_No SSL', 'SSL_CN_MLP_50prun0_HLCA_SSL', 'No_SSL_run0_HLCA_No SSL', 'SSL_CN_MLP_50prun1_SSL', 'SSL_CN_MLP_50prun2_SSL', 'CN_MLP_50prun1_Only Pretrained', 'CN_MLP_50prun2_Only Pretrained'])]\n",
    "\n",
    "# Ensure that the f1-score columns are of float type\n",
    "df['f1-score: accuracy'] = df['f1-score: accuracy'].astype(float)\n",
    "df['f1-score: macro avg'] = df['f1-score: macro avg'].astype(float)\n",
    "# Map the 'Model' column to colors\n",
    "# df['Color'] = df['Model'].map(color_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bfdfe1-497d-4f15-9cee-e8cab4be8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set the colors for each model type in the order you specified\n",
    "model_colors = [color_baseline, color_zeroshot, color_supervised, color_ssl]\n",
    "\n",
    "# Plot for Micro F1 Score\n",
    "plt.figure(figsize=(2.7, 2))\n",
    "ax1 = sns.boxplot(x='Model', y='f1-score: accuracy', data=df.sort_values('f1-score: accuracy'), linewidth=0.5, palette=model_colors)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), **tick_font)\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), **tick_font)\n",
    "ax1.set_xlabel('Model', fontdict=font)\n",
    "ax1.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax1.set_title('OOD Classification Performance\\nTail of Hippocampus (HiT) - Caudal Hippocampus - CA4-DGC', fontdict=font)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_HiT_Micro_F1_Boxplot.svg\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot for Macro F1 Score\n",
    "plt.figure(figsize=(2.7, 2))\n",
    "ax2 = sns.boxplot(x='Model', y='f1-score: macro avg', data=df.sort_values('f1-score: macro avg'), linewidth=0.5, palette=model_colors)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), **tick_font)\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), **tick_font)\n",
    "ax2.set_xlabel('Model', fontdict=font)\n",
    "ax2.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax2.set_title('OOD Classification Performance\\nTail of Hippocampus (HiT) - Caudal Hippocampus - CA4-DGC', fontdict=font)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_HiT_Macro_F1_Boxplot.svg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f85c2-5462-4a1b-86f7-dca6041af08c",
   "metadata": {},
   "source": [
    "**All non-neuronal cells**\n",
    "\n",
    "- 888,263 cells\n",
    "- 10x 3' v3\n",
    "- Bergmann glial cell (8041), astrocyte (155025), central nervous system macrophage (91383), ~~choroid plexus epithelial cell (7689)~~, endothelial cell (5165), ependymal cell (5882), ~~fibroblast (9156)~~, oligodendrocyte (494966), oligodendrocyte precursor cell (105734), pericyte (3693), vascular associated smooth muscle cell (1074)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341c6b0-8e84-43a4-98b9-1a7730229bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_OOD_nn_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6e749-4c2b-4905-8bf7-6449e7b3dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_type(row):\n",
    "    if 'Only Pretrained' in row['Unnamed: 0']:\n",
    "        return 'Zero-Shot\\nRandom Mask'\n",
    "    elif 'No SSL' in row['Unnamed: 0']:\n",
    "        return 'Supervised'\n",
    "    elif 'SSL_CN' in row['Unnamed: 0']:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'Random' in row['Unnamed: 0']:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return 'Error'\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['Model'] = df.apply(extract_model_type, axis=1)\n",
    "\n",
    "# Filter outliers\n",
    "df = df[~df['Unnamed: 0'].isin(['No_SSL_run0_No SSL', 'No_SSL_run4_No SSL', 'SSL_CN_MLP_50prun1_SSL', 'SSL_CN_MLP_50prun2_SSL', 'CN_MLP_50prun1_Only Pretrained', 'CN_MLP_50prun2_Only Pretrained'])]\n",
    "\n",
    "# Ensure that the f1-score columns are of float type\n",
    "df['f1-score: accuracy'] = df['f1-score: accuracy'].astype(float)\n",
    "df['f1-score: macro avg'] = df['f1-score: macro avg'].astype(float)\n",
    "\n",
    "# Map the 'Model' column to colors\n",
    "df['Color'] = df['Model'].map(color_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c1b8d-1bdc-420e-b539-6194f62b5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set the colors for each model type in the order you specified\n",
    "model_colors = [color_baseline, color_zeroshot, color_supervised, color_ssl]\n",
    "\n",
    "# Plot for Micro F1 Score\n",
    "plt.figure(figsize=(2.7, 2))  # Adjusted for consistency with other figures\n",
    "ax1 = sns.boxplot(x='Model', y='f1-score: accuracy', data=df.sort_values('f1-score: accuracy'), linewidth=0.5, palette=model_colors)\n",
    "# ax1.set_ylim(0.75, 1.0)  # Uncomment if you want to set a limit for the y-axis\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), **tick_font)\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax1.set_xlabel('Model', fontdict=font)\n",
    "ax1.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax1.set_title('OOD Classification Performance\\nBrain Atlas - Non-neuronal cells', fontdict=font)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_Brain_Atlas_Micro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n",
    "\n",
    "# Plot for Macro F1 Score\n",
    "plt.figure(figsize=(2.7, 2))  # Adjusted for consistency with other figures\n",
    "ax2 = sns.boxplot(x='Model', y='f1-score: macro avg', data=df.sort_values('f1-score: macro avg'), linewidth=0.5, palette=model_colors)\n",
    "# ax2.set_ylim(0.0, 1.0)  # Uncomment if you want to set a limit for the y-axis\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), **tick_font)\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax2.set_xlabel('Model', fontdict=font)\n",
    "ax2.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax2.set_title('OOD Classification Performance\\nBrain Atlas - Non-neuronal cells', fontdict=font)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_Brain_Atlas_Macro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d0c20-4d15-45db-98a6-a0286cfb9f02",
   "metadata": {},
   "source": [
    "### **Circulating Immune cells -- CV19 infection, vaccination and HC**\n",
    "\n",
    "- 195,632 cells\n",
    "- 10x 5' v1 10x 5' v2\n",
    "- B Cell (21190), CD4-positive, alpha-beta T cell (61350), CD8-positive, alpha-beta T cell (35752), T cell (1407), dendritic cell (3368), gamma-delta T cell (3184), monocyte (38476), mucosal invariant T cell (1244), natural killer cell (28834), stem cell (827) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b780dde-96aa-42ae-ae71-88a9a599e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_OOD_Circ_Imm_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33660712-88cf-4c63-bd89-29ab55dfd248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_type(row):\n",
    "    if 'Only Pretrained' in row['Unnamed: 0']:\n",
    "        return 'Zero-Shot\\nRandom Mask'\n",
    "    elif 'No SSL' in row['Unnamed: 0']:\n",
    "        return 'Supervised'\n",
    "    elif 'SSL_CN' in row['Unnamed: 0']:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'Random' in row['Unnamed: 0']:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return 'Error'\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['Model'] = df.apply(extract_model_type, axis=1)\n",
    "\n",
    "# Filter outliers\n",
    "# df = df[~df['Unnamed: 0'].isin(['No_SSL_run0_No SSL', 'No_SSL_run4_No SSL', 'SSL_CN_MLP_50prun1_SSL', 'SSL_CN_MLP_50prun2_SSL', 'CN_MLP_50prun1_Only Pretrained', 'CN_MLP_50prun2_Only Pretrained'])]\n",
    "\n",
    "# Ensure that the f1-score columns are of float type\n",
    "df['f1-score: accuracy'] = df['f1-score: accuracy'].astype(float)\n",
    "df['f1-score: macro avg'] = df['f1-score: macro avg'].astype(float)\n",
    "\n",
    "# Map the 'Model' column to colors\n",
    "df['Color'] = df['Model'].map(color_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f3da7-e677-4042-a68f-5442e885b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set the colors for each model type in the order you specified\n",
    "model_colors = [color_baseline, color_zeroshot, color_supervised, color_ssl]\n",
    "\n",
    "# Plot for Micro F1 Score\n",
    "plt.figure(figsize=(2.7, 2))  # Adjusted for consistency with other figures\n",
    "ax1 = sns.boxplot(x='Model', y='f1-score: accuracy', data=df.sort_values('f1-score: accuracy'), linewidth=0.5, palette=model_colors)\n",
    "# ax1.set_ylim(0.75, 1.0)  # Uncomment if you want to set a limit for the y-axis\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), **tick_font)\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax1.set_xlabel('Model', fontdict=font)\n",
    "ax1.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax1.set_title('OOD Classification Performance\\nCirculating Immune cells\\nCV19 infection, vaccination and HC', fontdict=font)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_Circ_Imm_Micro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n",
    "\n",
    "# Plot for Macro F1 Score\n",
    "\n",
    "# Calculate the mean f1-score for each model\n",
    "mean_scores = df.groupby('Model')['f1-score: macro avg'].mean().sort_values()\n",
    "\n",
    "# Create a list of models sorted by their mean f1-score\n",
    "sorted_models = mean_scores.index.tolist()\n",
    "\n",
    "plt.figure(figsize=(2.7, 2))  # Adjusted for consistency with other figures\n",
    "ax2 = sns.boxplot(x='Model', y='f1-score: macro avg', data=df.sort_values('f1-score: macro avg'), linewidth=0.5, palette=model_colors, order=sorted_models)\n",
    "# ax2.set_ylim(0.0, 1.0)  # Uncomment if you want to set a limit for the y-axis\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), **tick_font)\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax2.set_xlabel('Model', fontdict=font)\n",
    "ax2.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax2.set_title('OOD Classification Performance\\nCirculating Immune cells\\nCV19 infection, vaccination and HC', fontdict=font)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_Circ_Imm_Macro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e236e17-392a-426a-9deb-e499ea5f0340",
   "metadata": {},
   "source": [
    "### **Single-cell analysis of prenatal and postnatal human cortical development**\n",
    "\n",
    "- 709,372 cells\n",
    "- 110x 3' v2, 10x 3' v3, 10x multiome\n",
    "- astrocyte (67868), microglial cell (15857), native cell (15828), neural cell (537452), oligodendrocyte (40875), oligodendrocyte precursor cell (31392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71fbbe2-10a2-4e57-9ce6-bc5199bb7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_OOD_Cort_Dev_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba78e94-e994-443a-89a9-fb9c70ca0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_type(row):\n",
    "    if 'Only Pretrained' in row['Unnamed: 0']:\n",
    "        return 'Zero-Shot\\nRandom Mask'\n",
    "    elif 'No SSL' in row['Unnamed: 0']:\n",
    "        return 'Supervised'\n",
    "    elif 'SSL_CN' in row['Unnamed: 0']:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'Random' in row['Unnamed: 0']:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return 'Error'\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['Model'] = df.apply(extract_model_type, axis=1)\n",
    "\n",
    "# Filter outliers\n",
    "# df = df[~df['Unnamed: 0'].isin(['No_SSL_run0_No SSL', 'No_SSL_run4_No SSL', 'SSL_CN_MLP_50prun1_SSL', 'SSL_CN_MLP_50prun2_SSL', 'CN_MLP_50prun1_Only Pretrained', 'CN_MLP_50prun2_Only Pretrained'])]\n",
    "\n",
    "# Ensure that the f1-score columns are of float type\n",
    "df['f1-score: accuracy'] = df['f1-score: accuracy'].astype(float)\n",
    "df['f1-score: macro avg'] = df['f1-score: macro avg'].astype(float)\n",
    "\n",
    "# Map the 'Model' column to colors\n",
    "df['Color'] = df['Model'].map(color_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0727d6d-87e5-4042-b4af-a2cfa26e9df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set the colors for each model type in the order you specified\n",
    "model_colors = [color_baseline, color_zeroshot, color_supervised, color_ssl]\n",
    "\n",
    "# Plot for Micro F1 Score\n",
    "plt.figure(figsize=(2.7, 2))  # Adjusted for consistency with other figures\n",
    "ax1 = sns.boxplot(x='Model', y='f1-score: accuracy', data=df.sort_values('f1-score: accuracy'), linewidth=0.5, palette=model_colors)\n",
    "# ax1.set_ylim(0.75, 1.0)  # Uncomment if you want to set a limit for the y-axis\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), **tick_font)\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax1.set_xlabel('Model', fontdict=font)\n",
    "ax1.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax1.set_title('OOD Classification Performance\\nPrenatal and postnatal human cortical development', fontdict=font)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_Cort_Dev_Micro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n",
    "\n",
    "# Plot for Macro F1 Score\n",
    "\n",
    "# Calculate the mean f1-score for each model\n",
    "mean_scores = df.groupby('Model')['f1-score: macro avg'].mean().sort_values()\n",
    "\n",
    "# Create a list of models sorted by their mean f1-score\n",
    "sorted_models = mean_scores.index.tolist()\n",
    "\n",
    "plt.figure(figsize=(2.7, 2))  # Adjusted for consistency with other figures\n",
    "ax2 = sns.boxplot(x='Model', y='f1-score: macro avg', data=df.sort_values('f1-score: macro avg'), linewidth=0.5, palette=model_colors, order=sorted_models)\n",
    "# ax2.set_ylim(0.0, 1.0)  # Uncomment if you want to set a limit for the y-axis\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), **tick_font)\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax2.set_xlabel('Model', fontdict=font)\n",
    "ax2.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax2.set_title('OOD Classification Performance\\nPrenatal and postnatal human cortical development', fontdict=font)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_Cort_Dev_Macro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7a448-9396-42c6-8062-9b621b34ae1a",
   "metadata": {},
   "source": [
    "### **Human: Great apes study**\n",
    "\n",
    "- 156,285 cells\n",
    "- 10x 3' v3 Smart-seq v4\n",
    "- L2/3-6 intratelencephalic projecting glutamatergic cortical neuron (85276), L5 something not included (392), L6b glutamatergic cortical neuron (3415), astrocyte of the cerebral cortex (3047), caudial ganglio... not included (844), cerebral cortex endothelial cell (168), chandelier pval (728), cortocothalami... (3118), lamp5 GABAeric... (6416), microglial cell (1263), near-projecting ... (3461), oligodendrocyte (7876), oligodendrocyte precursor cell (2392), pvalb GABAergic (11778), sncg GABAergic (2025), sst GABAergic cortical interneuron (13593), vascular leptomeningeal cell (276), vip GABAergic cortical interneuron (10219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c5308-3920-46c7-bb85-5fe04f4deb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_OOD_Great_Apes_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64549f6-b7d9-4ced-bcbd-c5ba41547717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_type(row):\n",
    "    if 'Only Pretrained' in row['Unnamed: 0']:\n",
    "        return 'Zero-Shot\\nRandom Mask'\n",
    "    elif 'No SSL' in row['Unnamed: 0']:\n",
    "        return 'Supervised'\n",
    "    elif 'SSL_CN' in row['Unnamed: 0']:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'Random' in row['Unnamed: 0']:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return 'Error'\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['Model'] = df.apply(extract_model_type, axis=1)\n",
    "\n",
    "# Filter outliers\n",
    "# df = df[~df['Unnamed: 0'].isin(['No_SSL_run0_No SSL', 'No_SSL_run4_No SSL', 'SSL_CN_MLP_50prun1_SSL', 'SSL_CN_MLP_50prun2_SSL', 'CN_MLP_50prun1_Only Pretrained', 'CN_MLP_50prun2_Only Pretrained'])]\n",
    "\n",
    "# Ensure that the f1-score columns are of float type\n",
    "df['f1-score: accuracy'] = df['f1-score: accuracy'].astype(float)\n",
    "df['f1-score: macro avg'] = df['f1-score: macro avg'].astype(float)\n",
    "\n",
    "# Map the 'Model' column to colors\n",
    "df['Color'] = df['Model'].map(color_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709eafb-1940-4bff-b15a-e3666b413965",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std((0.211831, 0.164773, 0.240348, 0.107757, 0.173766))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9294c-9456-4af1-baba-e82022118654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set the colors for each model type in the order you specified\n",
    "model_colors = [color_baseline, color_zeroshot, color_supervised, color_ssl]\n",
    "\n",
    "# Plot for Micro F1 Score\n",
    "plt.figure(figsize=(2.7, 2))  # Adjusted for consistency with other figures\n",
    "ax1 = sns.boxplot(x='Model', y='f1-score: accuracy', data=df.sort_values('f1-score: accuracy'), linewidth=0.5, palette=model_colors)\n",
    "# ax1.set_ylim(0.75, 1.0)  # Uncomment if you want to set a limit for the y-axis\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), **tick_font)\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax1.set_xlabel('Model', fontdict=font)\n",
    "ax1.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax1.set_title('OOD Classification Performance\\nGreat Apes Study', fontdict=font)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_Great_Apes_Micro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n",
    "\n",
    "# Plot for Macro F1 Score\n",
    "\n",
    "# Calculate the mean f1-score for each model\n",
    "mean_scores = df.groupby('Model')['f1-score: macro avg'].mean().sort_values()\n",
    "\n",
    "# Create a list of models sorted by their mean f1-score\n",
    "sorted_models = mean_scores.index.tolist()\n",
    "\n",
    "plt.figure(figsize=(2.7, 2))  # Adjusted for consistency with other figures\n",
    "ax2 = sns.boxplot(x='Model', y='f1-score: macro avg', data=df.sort_values('f1-score: macro avg'), linewidth=0.5, palette=model_colors, order=sorted_models)\n",
    "# ax2.set_ylim(0.0, 1.0)  # Uncomment if you want to set a limit for the y-axis\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), **tick_font)\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), **tick_font)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax2.set_xlabel('Model', fontdict=font)\n",
    "ax2.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax2.set_title('OOD Classification Performance\\nGreat Apes Study', fontdict=font)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/OOD_Great_Apes_Macro_F1_Boxplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04ce82-efaf-41b8-8179-d31a46f12958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0430645-9b9a-4e1e-82e9-1eff621215f8",
   "metadata": {},
   "source": [
    "# Figure 3\n",
    "\n",
    "Does pretraining on a large, auxiliary dataset improve performance on a specific, known dataset to be classified?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9cf356-d43e-4175-9017-b9377b93b353",
   "metadata": {},
   "source": [
    "### 1. HLCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f443533-5649-4a37-bf89-1e47fd4d2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_hlca_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1cd64b-8ca0-44f3-9da8-8b6744022e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_select = ['CN_MLP_50p_Only Pretrained', \n",
    "                    'CN_MLP_50prun1_Only Pretrained', \n",
    "                    'CN_MLP_50prun2_Only Pretrained', \n",
    "                    'CN_MLP_50prun3_Only Pretrained', \n",
    "                    'CN_MLP_50prun4_Only Pretrained', \n",
    "                    'No_SSL_new_run0_HLCA_No SSL',\n",
    "                    'No_SSL_new_run1_HLCA_No SSL',\n",
    "                    'No_SSL_new_run2_HLCA_No SSL',\n",
    "                    'No_SSL_new_run3_HLCA_No SSL',\n",
    "                    'No_SSL_new_run4_HLCA_No SSL',\n",
    "                    'Random',\n",
    "                    'SSL_CN_MLP_50pnew_run0_HLCA_SSL',\n",
    "                    'SSL_CN_MLP_50prun1_HLCA_SSL',\n",
    "                    'SSL_CN_MLP_50prun2_HLCA_SSL',\n",
    "                    'SSL_CN_MLP_50prun3_HLCA_SSL',\n",
    "                    'SSL_CN_MLP_50prun4_HLCA_SSL',\n",
    "                   ]\n",
    "\n",
    "df_new_run = df[df['Unnamed: 0'].isin(models_to_select)]\n",
    "df_new_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d2666-3ce6-451a-9f75-e68f966e8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((0.744914, 0.782049, 0.809279, 0.787886, 0.737570))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f013a-c41f-4d0c-a54f-bb91c21aca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter to include only 'new_run' entries\n",
    "df_new_run = df[df['Unnamed: 0'].str.contains('new_run')]\n",
    "\n",
    "# Step 2: Rename model types\n",
    "def rename_model(row):\n",
    "    if 'Only Pretrained' in row:\n",
    "        return 'Zero-Shot\\nRandom Mask'\n",
    "    elif 'HLCA_No SSL' in row:\n",
    "        return 'Supervised'\n",
    "    elif 'HLCA_SSL' in row:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'Random' in row:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "df_new_run['Unnamed: 0'] = df_new_run['Unnamed: 0'].apply(rename_model)\n",
    "\n",
    "model_colors = [color_baseline, color_zeroshot, color_supervised, color_ssl]\n",
    "\n",
    "# Step 3: Calculate mean and std for each model\n",
    "mean_std_df = df_new_run.groupby('Unnamed: 0')['f1-score: macro avg', 'f1-score: accuracy'].agg(['mean', 'std'])\n",
    "\n",
    "# Step 4: Create box plots\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties\n",
    "font = {'family': 'sans-serif', 'size': 5}  # This will be for titles and labels\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(3,2))\n",
    "ax = sns.boxplot(x='Unnamed: 0', y='f1-score: accuracy', data=df_new_run.sort_values('f1-score: accuracy'), linewidth=0.5, palette=model_colors)\n",
    "ax.set_xlabel('Model', fontdict=font)\n",
    "ax.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax.set_title('HLCA Classification Performance', fontdict=font)\n",
    "\n",
    "# Set font for all tick labels to match the fontdict\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font)\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/HLCA_Clf_Micro_F1.svg\", bbox_inches='tight')  # Save as SVG\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Repeat for the second plot\n",
    "plt.figure(figsize=(3, 2))\n",
    "ax = sns.boxplot(x='Unnamed: 0', y='f1-score: macro avg', data=df_new_run.sort_values('f1-score: macro avg'), linewidth=0.5, palette=model_colors)\n",
    "ax.set_xlabel('Model', fontdict=font)\n",
    "ax.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax.set_title('HLCA Classification Performance', fontdict=font)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font)\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/HLCA_Clf_Macro_F1.svg\", bbox_inches='tight')  # Save as SVG\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d84b362-d80d-493d-8f45-1b16b008eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter to include only 'new_run' entries\n",
    "df_new_run = df# [df['Unnamed: 0'].str.contains('new_run')]\n",
    "\n",
    "# Step 2: Rename model types\n",
    "def rename_model(row):\n",
    "    if 'SSL_CN' in row:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'No SSL' in row:\n",
    "        return 'Supervised'\n",
    "    elif 'Only Pretrained' in row:\n",
    "        return \"Zero-Shot\\nRandom Mask\"\n",
    "    elif 'Random' in row:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "df_new_run['Unnamed: 0'] = df_new_run['Unnamed: 0'].apply(rename_model)\n",
    "\n",
    "# Step 3: Calculate mean and std for each model\n",
    "mean_std_df = df_new_run.groupby('Unnamed: 0')['f1-score: macro avg', 'f1-score: accuracy'].agg(['mean', 'std'])\n",
    "\n",
    "# Map the 'Model' column to colors\n",
    "df_new_run['Color'] = df_new_run['Unnamed: 0'].map(color_dict)\n",
    "\n",
    "df_new_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96065a0c-0fad-4d1d-b669-63a444f13dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate color palette based on sorted model order\n",
    "def get_palette(df, col_name):\n",
    "    sorted_models = df.sort_values(col_name)['Unnamed: 0'].unique()\n",
    "    return [color_dict[model] for model in sorted_models]\n",
    "\n",
    "# Plot for Micro F1 Score\n",
    "plt.figure(figsize=(3, 2))\n",
    "palette = get_palette(df_new_run, 'f1-score: accuracy')\n",
    "ax = sns.boxplot(x='Unnamed: 0', y='f1-score: accuracy', data=df_new_run.sort_values('f1-score: accuracy'), linewidth=0.5, palette=palette)\n",
    "ax.set_xlabel('Model', fontdict=font)\n",
    "ax.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax.set_title('HLCA Classification Performance', fontdict=font)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font)\n",
    "# plt.savefig(RESULTS_FOLDER + \"/classification/HLCA_Clf_Micro_F1.svg\", bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Repeat for the second plot\n",
    "plt.figure(figsize=(3, 2))\n",
    "palette = get_palette(df_new_run, 'f1-score: macro avg')\n",
    "ax = sns.boxplot(x='Unnamed: 0', y='f1-score: macro avg', data=df_new_run.sort_values('f1-score: macro avg'), linewidth=0.5, palette=palette)\n",
    "ax.set_xlabel('Model', fontdict=font)\n",
    "ax.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax.set_title('HLCA Classification Performance', fontdict=font)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font)\n",
    "# plt.savefig(RESULTS_FOLDER + \"/classification/HLCA_Clf_Macro_F1.svg\", bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d62d70-4ba3-4a75-be8a-da15acac9dfa",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ff082b-6cb7-47f5-9781-c5e3fbd7a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_per_class_report_hlca_merged_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b4706-4cf5-4d0d-b2f6-c9f842814461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a colorblind-friendly palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "colors = sns.color_palette()\n",
    "\n",
    "# Define font properties\n",
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust the size as needed\n",
    "\n",
    "# Create a JointGrid with specified height\n",
    "g = sns.JointGrid(x='Cell Count', y='F1_Supervised', data=df, height=3, marginal_ticks=True, space=0.2)\n",
    "g = g.plot_joint(plt.scatter, s=6, color=colors[0], label=\"Supervised\")  # Model A in one color\n",
    "g.ax_joint.scatter(df['Cell Count'], df['F1_Self-Supervised'], s=5, color=colors[1], label=\"Self Supervised\")  # Model B in another color\n",
    "\n",
    "# Histograms\n",
    "g.ax_marg_x.hist(df['Cell Count'], bins=np.geomspace(df['Cell Count'].min(), df['Cell Count'].max(), 20), alpha=.6, edgecolor='black', color=colors[2])\n",
    "g.ax_marg_y.hist(df['F1_Supervised'], bins=np.linspace(0, 1, 20), alpha=.6, orientation='horizontal', edgecolor='black', color=colors[0])\n",
    "g.ax_marg_y.hist(df['F1_Self-Supervised'], bins=np.linspace(0, 1, 20), alpha=.6, orientation='horizontal', edgecolor='black', color=colors[1])\n",
    "\n",
    "# Labels & Title\n",
    "g.set_axis_labels('Number of Cells per Cell Type (log scale)', 'F1-Score per Cell Type', **font)\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "# Adjust legend with font properties\n",
    "g.ax_joint.legend(prop=font)\n",
    "\n",
    "# Apply font properties to all tick labels\n",
    "for ax in [g.ax_joint, g.ax_marg_x, g.ax_marg_y]:\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        label.set_fontsize(font['size'])\n",
    "        label.set_family(font['family'])\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/HLCA_per_celltype_perf.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5193db2-9a96-4254-ba67-75b784d511c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between F1 scores of Self-Supervised and Supervised\n",
    "df['F1_Difference'] = df['F1_Self-Supervised'] - df['F1_Supervised']\n",
    "\n",
    "# Filter the data for positive, negative, and equal non-zero F1_Difference\n",
    "positive_diff = df[df['F1_Difference'] > 0]\n",
    "negative_diff = df[df['F1_Difference'] < 0]\n",
    "equal_non_zero_diff = df[(df['F1_Difference'] == 0)] # & (df['F1_Self-Supervised'] != 0) & (df['F1_Supervised'] != 0)]\n",
    "\n",
    "# Create a JointGrid without the right histogram (deactivate marginal plots)\n",
    "g = sns.JointGrid(x='Cell Count', y='F1_Difference', data=df, height=2.5, marginal_ticks=True, space=0.2)\n",
    "\n",
    "# Plot the scatter points with color depending on the sign of the F1_Difference\n",
    "# Points where Self-Supervised is better (positive difference)\n",
    "g.ax_joint.scatter(positive_diff['Cell Count'], positive_diff['F1_Difference'], \n",
    "                   s=5, color=color_ssl, label=\"Self-Supervised Better\")\n",
    "\n",
    "# Points where Supervised is better (negative difference)\n",
    "g.ax_joint.scatter(negative_diff['Cell Count'], negative_diff['F1_Difference'], \n",
    "                   s=5, color=color_supervised, label=\"Supervised Better\")\n",
    "\n",
    "# Points where performance is equal and non-zero\n",
    "# g.ax_joint.scatter(equal_non_zero_diff['Cell Count'], equal_non_zero_diff['F1_Difference'], \n",
    "#                    s=5, color=color_else2, label=\"Equal Performance (F1=0)\")\n",
    "\n",
    "# Histogram on the top\n",
    "g.ax_marg_x.hist(df['Cell Count'], bins=np.geomspace(df['Cell Count'].min(), df['Cell Count'].max(), 20), \n",
    "                 alpha=.6, edgecolor='black', color='grey')\n",
    "\n",
    "# Labels & Title\n",
    "g.set_axis_labels('Number of Cells per Cell Type (log scale)', 'Performance Difference (Δ Macro F1)', **font)\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "# Adjust legend with font properties\n",
    "g.ax_joint.legend(prop=font)\n",
    "\n",
    "# Apply font properties to all tick labels\n",
    "for label in g.ax_joint.get_xticklabels() + g.ax_joint.get_yticklabels():\n",
    "    label.set_fontsize(font['size'])\n",
    "    label.set_family(font['family'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/HLCA_Per_CT_Difference.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58078f4-4b35-45dc-bd96-c551ddd321ec",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8a348-d01e-4fd9-8ef7-f9246b0af388",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_supervised = np.load(os.path.join(RESULTS_FOLDER, 'classification', 'new_predicted_labels_No_SSL_new_run1_HLCA_No SSL.npy'))\n",
    "y_pred_ssl = np.load(os.path.join(RESULTS_FOLDER, 'classification', 'new_predicted_labels_SSL_CN_MLP_50prun4_HLCA_SSL.npy'))\n",
    "y_true = np.load(os.path.join(RESULTS_FOLDER, 'classification', 'new_true_labels_No_SSL_new_run1_HLCA_No SSL.npy'))  # same as for ssl, deterministic data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4454c53-32be-4d16-b706-0a82dc21d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correct predictions\n",
    "correct_supervised = np.equal(y_pred_supervised, y_true).astype(int)\n",
    "correct_ssl = np.equal(y_pred_ssl, y_true).astype(int)\n",
    "\n",
    "# Calculate the sum of correct predictions for each class\n",
    "unique_classes = np.unique(y_true)\n",
    "correct_counts_supervised = [np.sum(correct_supervised[y_true == cls]) for cls in unique_classes]\n",
    "correct_counts_ssl = [np.sum(correct_ssl[y_true == cls]) for cls in unique_classes]\n",
    "\n",
    "# Calculate the differences\n",
    "differences = np.array(correct_counts_ssl) - np.array(correct_counts_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488f199-e8ef-4d55-9d77-75aff9e929dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896da3d-45e4-4312-9d51-cb2c7ad2fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_mapping = pd.read_parquet(\n",
    "        os.path.join(STORE_DIR, \"categorical_lookup/cell_type.parquet\")\n",
    "    )\n",
    "cell_type_mapping['label'] = cell_type_mapping['label'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcc7ff6-8a9f-45bb-a48b-7a8531903543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for plotting\n",
    "df_plot = pd.DataFrame({\n",
    "    'Class': unique_classes,\n",
    "    'Difference': differences\n",
    "})\n",
    "\n",
    "# Sort by absolute difference and select top n classes\n",
    "n = 6  # Replace with your desired number of classes\n",
    "df_plot['Absolute Difference'] = df_plot['Difference'].abs()\n",
    "df_top_n = df_plot.sort_values(by='Absolute Difference', ascending=False).head(n)\n",
    "\n",
    "\n",
    "\n",
    "# Assign colors based on the sign of the difference\n",
    "df_top_n['Color'] = df_top_n['Difference'].apply(lambda x: color_ssl if x > 0 else color_supervised)\n",
    "\n",
    "# Create a mapping dictionary from integer labels to string names\n",
    "label_to_name_dict = cell_type_mapping['label'].to_dict()\n",
    "\n",
    "# Replace integer class labels in df_top_n with string names\n",
    "df_top_n['Class'] = df_top_n['Class'].map(label_to_name_dict)\n",
    "\n",
    "# Plotting\n",
    "bar_colors = [color_ssl, color_ssl, color_ssl, color_supervised, color_supervised, color_ssl]\n",
    "\n",
    "plt.figure(figsize=(2.5, 2.5))\n",
    "ax = sns.barplot(x='Class', y='Difference', data=df_top_n, palette=bar_colors)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, **tick_font, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=45, **tick_font, ha='right')\n",
    "ax.set_xlabel('Class', fontdict=font)\n",
    "ax.set_ylabel('Δ Correct Predictions', fontdict=font)\n",
    "ax.set_title('HLCA Cell Type Prediction Difference', fontdict=font)\n",
    "\n",
    "# Annotate bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=font['size'])\n",
    "    \n",
    "# Create legend handles\n",
    "ssl_patch = mpatches.Patch(color=color_ssl, label='Self-Supervised Better')\n",
    "supervised_patch = mpatches.Patch(color=color_supervised, label='Supervised Better')\n",
    "\n",
    "# Add legend to the plot\n",
    "ax.legend(handles=[ssl_patch, supervised_patch], loc='upper right', prop=font)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/hlca_biggest_difference_barplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115bc11-c67e-40f3-a7a9-bc34056dddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_supervised = pd.read_csv(os.path.join(RESULTS_FOLDER, 'classification', 'conf_matrix_No_SSL_new_run1_HLCA_No SSL.csv'), index_col='Unnamed: 0')\n",
    "conf_matrix_ssl = pd.read_csv(os.path.join(RESULTS_FOLDER, 'classification', 'conf_matrix_SSL_CN_MLP_50prun4_HLCA_SSL.csv'), index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dbce0b-933c-4c4a-bdeb-6cec7f50cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Compute the difference matrix\n",
    "conf_matrix_difference = conf_matrix_ssl - conf_matrix_supervised\n",
    "\n",
    "# Identify the top N cell types with the largest absolute differences\n",
    "N = 5  # Number of top differences to display\n",
    "top_differences = conf_matrix_difference.abs().sum(axis=1).nlargest(N).index\n",
    "\n",
    "# Create a subset DataFrame for these top differences\n",
    "conf_matrix_subset = conf_matrix_difference.loc[top_differences, top_differences]\n",
    "\n",
    "# Capitalize the first letter of each word in the columns\n",
    "conf_matrix_subset.columns = conf_matrix_subset.columns.str.title()\n",
    "\n",
    "# Capitalize the first letter of each word in the index\n",
    "conf_matrix_subset.index = conf_matrix_subset.index.str.title()\n",
    "\n",
    "# Create a custom diverging colormap\n",
    "top = mcolors.to_rgba(color_ssl)\n",
    "bottom = mcolors.to_rgba(color_supervised)\n",
    "custom_colormap = mcolors.LinearSegmentedColormap.from_list(\"custom_map\", [bottom, \"white\", top])\n",
    "\n",
    "# Define the range for the colormap\n",
    "max_abs_value = np.abs(conf_matrix_subset.values).max()\n",
    "vmin, vmax = -max_abs_value, max_abs_value\n",
    "\n",
    "# Create heatmap without annotations for the subset difference matrix\n",
    "plt.figure(figsize=(1.5, 1.2))  # Adjust figure size as needed for better visibility\n",
    "ax = sns.heatmap(conf_matrix_subset, annot=False, cmap=custom_colormap, linewidths=.5, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(conf_matrix_subset.columns, **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(conf_matrix_subset.index, **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('HLCA Performance Difference', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/hlca_biggest_difference_confusion_matrix.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b4140-f156-400c-b4a4-30a17aabb110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference matrix\n",
    "conf_matrix_difference = conf_matrix_ssl - conf_matrix_supervised\n",
    "\n",
    "# Create a custom diverging colormap\n",
    "top = mcolors.to_rgba(color_ssl)\n",
    "bottom = mcolors.to_rgba(color_supervised)\n",
    "custom_colormap = mcolors.LinearSegmentedColormap.from_list(\"custom_map\", [bottom, \"white\", top])\n",
    "\n",
    "# Create heatmap without annotations for the difference matrix\n",
    "plt.figure(figsize=(10, 8))  # Adjust figure size as needed for better visibility\n",
    "ax = sns.heatmap(conf_matrix_difference, annot=False, cmap=custom_colormap, linewidths=.5)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(conf_matrix_difference.columns, **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(conf_matrix_difference.index, **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('HLCA Performance Difference: Self-Supervised vs Supervised Model\\n(Positive: More Counts Self-Supervised, Negative: More Counts Supervised)', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/hlca_difference_confusion_matrix.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb8f63-d04e-4622-91b5-2dd4f830d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for the plots\n",
    "sns.set_theme()\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties for titles and labels\n",
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust size as needed\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}  # Adjust font size for tick labels\n",
    "\n",
    "# Create heatmap without annotations\n",
    "plt.figure(figsize=(5, 4))  # Adjust figure size as needed\n",
    "ax = sns.heatmap(conf_matrix_supervised, annot=False, cmap='viridis', linewidths=.5)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('HLCA Confusion Matrix Supervised Model', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/confusion_matrix_hlca_supervised.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91574fe6-a26b-475b-83b9-29715020e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for the plots\n",
    "sns.set_theme()\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties for titles and labels\n",
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust size as needed\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}  # Adjust font size for tick labels\n",
    "\n",
    "# Create heatmap without annotations\n",
    "plt.figure(figsize=(5, 4))  # Adjust figure size as needed\n",
    "ax = sns.heatmap(conf_matrix_ssl, annot=False, cmap='viridis', linewidths=.5)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('HLCA Confusion Matrix Self-Supervised Model', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/confusion_matrix_hlca_ssl.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa6fe52-f87d-4af9-8f46-d09bd54dbc22",
   "metadata": {},
   "source": [
    "### 2. PBMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562af984-3fa3-43f3-90d2-8b169d9ab01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_pbmc_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Identify the rows to be dropped by their index values\n",
    "rows_to_drop = ['No_SSL_new_run5_PBMC_No SSL', 'No_SSL_new_run2_PBMC_No SSL', 'No_SSL_run0_PBMC_No SSL']\n",
    "\n",
    "# Drop the specified rows\n",
    "df = df[~df['Unnamed: 0'].isin(rows_to_drop)]\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ecd5fb-2183-4357-8510-002387875457",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_select = ['CN_MLP_50p_Only Pretrained', \n",
    "                    'CN_MLP_50prun1_Only Pretrained', \n",
    "                    'CN_MLP_50prun2_Only Pretrained', \n",
    "                    'CN_MLP_50prun3_Only Pretrained', \n",
    "                    'CN_MLP_50prun4_Only Pretrained', \n",
    "                    'No_SSL_new_run0_PBMC_No SSL',\n",
    "                    'No_SSL_new_run1_PBMC_No SSL',\n",
    "                    'No_SSL_new_run2_PBMC_No SSL',\n",
    "                    'No_SSL_new_run3_PBMC_No SSL',\n",
    "                    'No_SSL_new_run4_PBMC_No SSL',\n",
    "                    'Random',\n",
    "                    'SSL_CN_MLP_50pnew_run0_PBMC_SSL',\n",
    "                    'SSL_CN_MLP_50pnew_run1_PBMC_SSL',\n",
    "                    'SSL_CN_MLP_50pnew_run2_PBMC_SSL',\n",
    "                    'SSL_CN_MLP_50pnew_run3_PBMC_SSL',\n",
    "                    'SSL_CN_MLP_50pnew_run4_PBMC_SSL',\n",
    "                   ]\n",
    "\n",
    "df_new_run = df[df['Unnamed: 0'].isin(models_to_select)]\n",
    "df_new_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e38e1-8dcc-4821-82c4-c2d561ce0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((0.657838, 0.681130, 0.727992, 0.702843, 0.674552))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd8f02-4ddd-4e85-9a4c-18838c07f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter to include only 'new_run' entries\n",
    "df_new_run = df[df['Unnamed: 0'].str.contains('new_run')]\n",
    "\n",
    "# Step 2: Rename model types\n",
    "def rename_model(row):\n",
    "    if 'PBMC_SSL' in row:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'No SSL' in row:\n",
    "        return 'Supervised'\n",
    "    elif 'Only Pretrained' in row:\n",
    "        return 'Zero-Shot\\nRandom Mask'\n",
    "    elif 'Random' in row:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "df_new_run['Unnamed: 0'] = df_new_run['Unnamed: 0'].apply(rename_model)\n",
    "\n",
    "model_colors = [color_baseline, color_zeroshot, color_supervised, color_ssl]\n",
    "\n",
    "# Step 3: Calculate mean and std for each model\n",
    "mean_std_df = df_new_run.groupby('Unnamed: 0')['f1-score: macro avg', 'f1-score: accuracy'].agg(['mean', 'std'])\n",
    "\n",
    "# Step 4: Create box plots\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties\n",
    "font = {'family': 'sans-serif', 'size': 5}  # This will be for titles and labels\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(3,2))\n",
    "ax = sns.boxplot(x='Unnamed: 0', y='f1-score: accuracy', data=df_new_run.sort_values('f1-score: accuracy'), linewidth=0.5, palette=model_colors)\n",
    "ax.set_xlabel('Model', fontdict=font)\n",
    "ax.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax.set_title('PBMC Classification Performance', fontdict=font)\n",
    "\n",
    "# Set font for all tick labels to match the fontdict\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font)\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/PBMC_Clf_Micro_F1.svg\", bbox_inches='tight')  # Save as SVG\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Repeat for the second plot\n",
    "plt.figure(figsize=(3, 2))\n",
    "ax = sns.boxplot(x='Unnamed: 0', y='f1-score: macro avg', data=df_new_run.sort_values('f1-score: macro avg'), linewidth=0.5, palette=model_colors)\n",
    "ax.set_xlabel('Model', fontdict=font)\n",
    "ax.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax.set_title('PBMC Classification Performance', fontdict=font)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font)\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/PBMC_Clf_Macro_F1.svg\", bbox_inches='tight')  # Save as SVG\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0b532-aedd-46b5-88a8-3b1db6666e60",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef310db-14dd-4d5c-a136-ba717135d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_per_class_report_pbmc_merged_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e68dc-ed26-4358-a28c-9f63384b708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a colorblind-friendly palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "colors = sns.color_palette()\n",
    "\n",
    "# Define font properties\n",
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust the size as needed\n",
    "\n",
    "# Create a JointGrid with specified height\n",
    "g = sns.JointGrid(x='Cell Count', y='F1_Supervised', data=df, height=3, marginal_ticks=True, space=0.2)\n",
    "g = g.plot_joint(plt.scatter, s=6, color=colors[0], label=\"Supervised\")  # Model A in one color\n",
    "g.ax_joint.scatter(df['Cell Count'], df['F1_Self-Supervised'], s=6, color=colors[1], label=\"Self Supervised\")  # Model B in another color\n",
    "\n",
    "# Histograms\n",
    "g.ax_marg_x.hist(df['Cell Count'], bins=np.geomspace(df['Cell Count'].min(), df['Cell Count'].max(), 20), alpha=.6, edgecolor='black', color=colors[2])\n",
    "g.ax_marg_y.hist(df['F1_Supervised'], bins=np.linspace(0, 1, 20), alpha=.6, orientation='horizontal', edgecolor='black', color=colors[0])\n",
    "g.ax_marg_y.hist(df['F1_Self-Supervised'], bins=np.linspace(0, 1, 20), alpha=.6, orientation='horizontal', edgecolor='black', color=colors[1])\n",
    "\n",
    "# Labels & Title\n",
    "g.set_axis_labels('Number of Cells per Cell Type (log scale)', 'F1-Score per Cell Type', **font)\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "# Adjust legend with font properties\n",
    "g.ax_joint.legend(prop=font)\n",
    "\n",
    "# Apply font properties to all tick labels\n",
    "for ax in [g.ax_joint, g.ax_marg_x, g.ax_marg_y]:\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        label.set_fontsize(font['size'])\n",
    "        label.set_family(font['family'])\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/PBMC_per_celltype_perf.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4b955-2c56-47d5-b41b-800386f444e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between F1 scores of Self-Supervised and Supervised\n",
    "df['F1_Difference'] = df['F1_Self-Supervised'] - df['F1_Supervised']\n",
    "\n",
    "# Filter the data for positive, negative, and equal non-zero F1_Difference\n",
    "positive_diff = df[df['F1_Difference'] > 0]\n",
    "negative_diff = df[df['F1_Difference'] < 0]\n",
    "equal_non_zero_diff = df[(df['F1_Difference'] == 0)] # & (df['F1_Self-Supervised'] != 0) & (df['F1_Supervised'] != 0)]\n",
    "\n",
    "# Create a JointGrid without the right histogram (deactivate marginal plots)\n",
    "g = sns.JointGrid(x='Cell Count', y='F1_Difference', data=df, height=2.5, marginal_ticks=True, space=0.2)\n",
    "\n",
    "# Plot the scatter points with color depending on the sign of the F1_Difference\n",
    "# Points where Self-Supervised is better (positive difference)\n",
    "g.ax_joint.scatter(positive_diff['Cell Count'], positive_diff['F1_Difference'], \n",
    "                   s=5, color=color_ssl, label=\"Self-Supervised Better\")\n",
    "\n",
    "# Points where Supervised is better (negative difference)\n",
    "g.ax_joint.scatter(negative_diff['Cell Count'], negative_diff['F1_Difference'], \n",
    "                   s=5, color=color_supervised, label=\"Supervised Better\")\n",
    "\n",
    "# Points where performance is equal and non-zero\n",
    "g.ax_joint.scatter(equal_non_zero_diff['Cell Count'], equal_non_zero_diff['F1_Difference'], \n",
    "                   s=5, color=color_else2, label=\"Equal Performance (F1=0)\")\n",
    "\n",
    "# Histogram on the top\n",
    "g.ax_marg_x.hist(df['Cell Count'], bins=np.geomspace(df['Cell Count'].min(), df['Cell Count'].max(), 20), \n",
    "                 alpha=.6, edgecolor='black', color='grey')\n",
    "\n",
    "# Labels & Title\n",
    "g.set_axis_labels('Number of Cells per Cell Type (log scale)', 'Performance Difference (Δ Macro F1)', **font)\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "# Adjust legend with font properties\n",
    "g.ax_joint.legend(prop=font)\n",
    "\n",
    "# Apply font properties to all tick labels\n",
    "for label in g.ax_joint.get_xticklabels() + g.ax_joint.get_yticklabels():\n",
    "    label.set_fontsize(font['size'])\n",
    "    label.set_family(font['family'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/PBMC_Per_CT_Difference.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97077663-bff0-43e1-bf43-f85d053d0d46",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f34ce-1241-4ee6-9f01-965a55592aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_supervised = np.load(os.path.join(RESULTS_FOLDER, 'classification', 'new_predicted_labels_No_SSL_run2_PBMC_No SSL.npy'))\n",
    "y_pred_ssl = np.load(os.path.join(RESULTS_FOLDER, 'classification', 'new_predicted_labels_SSL_CN_MLP_50pnew_run2_PBMC_SSL.npy'))\n",
    "y_true = np.load(os.path.join(RESULTS_FOLDER, 'classification', 'new_true_labels_No_SSL_run2_PBMC_No SSL.npy'))  # same as for ssl, deterministic data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef63b1-0b3a-479d-999c-81c83d4ff904",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_ssl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37bc1e-14fe-4f41-a2c6-92296adba968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correct predictions\n",
    "correct_supervised = np.equal(y_pred_supervised, y_true).astype(int)\n",
    "correct_ssl = np.equal(y_pred_ssl, y_true).astype(int)\n",
    "\n",
    "# Calculate the sum of correct predictions for each class\n",
    "unique_classes = np.unique(y_true)\n",
    "correct_counts_supervised = [np.sum(correct_supervised[y_true == cls]) for cls in unique_classes]\n",
    "correct_counts_ssl = [np.sum(correct_ssl[y_true == cls]) for cls in unique_classes]\n",
    "\n",
    "# Calculate the differences\n",
    "differences = np.array(correct_counts_ssl) - np.array(correct_counts_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4635116-8b1e-4001-822f-bd5a224b31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_mapping = pd.read_parquet(\n",
    "        os.path.join(STORE_DIR, \"categorical_lookup/cell_type.parquet\")\n",
    "    )\n",
    "cell_type_mapping['label'] = cell_type_mapping['label'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f63e29-d011-46e5-897c-1629af1a3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for plotting\n",
    "df_plot = pd.DataFrame({\n",
    "    'Class': unique_classes,\n",
    "    'Difference': differences\n",
    "})\n",
    "\n",
    "# Sort by absolute difference and select top n classes\n",
    "n = 6  # Replace with your desired number of classes\n",
    "df_plot['Absolute Difference'] = df_plot['Difference'].abs()\n",
    "df_top_n = df_plot.sort_values(by='Absolute Difference', ascending=False).head(n)\n",
    "\n",
    "# Assign colors based on the sign of the difference\n",
    "df_top_n['Color'] = df_top_n['Difference'].apply(lambda x: color_ssl if x > 0 else color_supervised)\n",
    "\n",
    "# Create a mapping dictionary from integer labels to string names\n",
    "label_to_name_dict = cell_type_mapping['label'].to_dict()\n",
    "\n",
    "# Replace integer class labels in df_top_n with string names\n",
    "df_top_n['Class'] = df_top_n['Class'].map(label_to_name_dict)\n",
    "\n",
    "# Plotting\n",
    "bar_colors = [color_ssl, color_ssl, color_ssl, color_ssl, color_ssl, color_ssl]\n",
    "\n",
    "plt.figure(figsize=(2.5, 1.5))\n",
    "ax = sns.barplot(x='Class', y='Difference', data=df_top_n, palette=bar_colors)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, **tick_font, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=45, **tick_font, ha='right')\n",
    "ax.set_xlabel('Class', fontdict=font)\n",
    "ax.set_ylabel('Δ Correct Predictions', fontdict=font)\n",
    "ax.set_title('PBMC Cell Type Prediction Difference', fontdict=font)\n",
    "\n",
    "# Annotate bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=font['size'])\n",
    "# Create legend handles\n",
    "ssl_patch = mpatches.Patch(color=color_ssl, label='Self-Supervised Better')\n",
    "supervised_patch = mpatches.Patch(color=color_supervised, label='Supervised Better')\n",
    "\n",
    "# Add legend to the plot\n",
    "ax.legend(handles=[ssl_patch, supervised_patch], loc='upper right', prop=font)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/pbmc_biggest_difference_barplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e058d0d-e032-4828-b569-0f5df31f42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference matrix\n",
    "conf_matrix_difference = conf_matrix_ssl - conf_matrix_supervised\n",
    "\n",
    "# Create a custom diverging colormap\n",
    "top = mcolors.to_rgba(color_ssl)\n",
    "bottom = mcolors.to_rgba(color_supervised)\n",
    "custom_colormap = mcolors.LinearSegmentedColormap.from_list(\"custom_map\", [bottom, \"white\", top])\n",
    "\n",
    "# Create heatmap without annotations for the difference matrix\n",
    "plt.figure(figsize=(10, 8))  # Adjust figure size as needed for better visibility\n",
    "ax = sns.heatmap(conf_matrix_difference, annot=False, cmap=custom_colormap, linewidths=.5)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(conf_matrix_difference.columns, **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(conf_matrix_difference.index, **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('PBMC Performance Difference: Self-Supervised vs Supervised Model\\n(Positive: More Counts Self-Supervised, Negative: More Counts Supervised)', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/pbmc_difference_confusion_matrix.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8e305-8c73-4b18-8dcf-dc5d2d3d9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for the plots\n",
    "sns.set_theme()\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties for titles and labels\n",
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust size as needed\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}  # Adjust font size for tick labels\n",
    "\n",
    "# Create heatmap without annotations\n",
    "plt.figure(figsize=(5, 4))  # Adjust figure size as needed\n",
    "ax = sns.heatmap(conf_matrix_supervised, annot=False, cmap='viridis', linewidths=.5)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('PBMC Confusion Matrix Supervised Model', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/confusion_matrix_pbmc_supervised.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c73d01-d70d-4916-968d-140a9c84d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for the plots\n",
    "sns.set_theme()\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties for titles and labels\n",
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust size as needed\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}  # Adjust font size for tick labels\n",
    "\n",
    "# Create heatmap without annotations\n",
    "plt.figure(figsize=(5, 4))  # Adjust figure size as needed\n",
    "ax = sns.heatmap(conf_matrix_ssl, annot=False, cmap='viridis', linewidths=.5)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('PBMC Confusion Matrix Self-Supervised Model', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/confusion_matrix_pbmc_ssl.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b40ca2-2f74-408a-959d-cb768dc0d44b",
   "metadata": {},
   "source": [
    "### 3. Tabula Sapiens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b0495-0f58-481c-993a-9f9d1c499bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_report_tabula_sapiens_knn.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94232f1-002c-4a37-a5bf-adca8e0df9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_select = ['CN_MLP_50p_Only Pretrained', \n",
    "                    'CN_MLP_50prun1_Only Pretrained', \n",
    "                    'CN_MLP_50prun2_Only Pretrained', \n",
    "                    'CN_MLP_50prun3_Only Pretrained', \n",
    "                    'CN_MLP_50prun4_Only Pretrained', \n",
    "                    'No_SSL_new_run0_Tabula_Sapiens_No SSL',\n",
    "                    'No_SSL_new_run1_Tabula_Sapiens_No SSL',\n",
    "                    'No_SSL_new_run2_Tabula_Sapiens_No SSL',\n",
    "                    'No_SSL_new_run3_Tabula_Sapiens_No SSL',\n",
    "                    'No_SSL_new_run4_Tabula_Sapiens_No SSL',\n",
    "                    'Random',\n",
    "                    'SSL_CN_MLP_50pnew_run0_Tabula_Sapiens_SSL',\n",
    "                    'SSL_CN_MLP_50pnew_run1_Tabula_Sapiens_SSL',\n",
    "                    'SSL_CN_MLP_50pnew_run2_Tabula_Sapiens_SSL',\n",
    "                    'SSL_CN_MLP_50pnew_run3_Tabula_Sapiens_SSL',\n",
    "                    'SSL_CN_MLP_50pnew_run4_Tabula_Sapiens_SSL',\n",
    "                   ]\n",
    "\n",
    "df_new_run = df[df['Unnamed: 0'].isin(models_to_select)]\n",
    "df_new_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457f255-e273-42df-bf71-5272e5f16e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((0.378728, 0.333734, 0.415839, 0.366523, 0.372547))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850231a-b091-4b2b-a747-b1beb2c7fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter to include only 'new_run' entries\n",
    "df_new_run = df[df['Unnamed: 0'].str.contains('new_run')]\n",
    "\n",
    "# Step 2: Rename model types\n",
    "def rename_model(row):\n",
    "    if 'SSL_CN' in row:\n",
    "        return 'Self-Supervised\\nRandom Mask'\n",
    "    elif 'No SSL' in row:\n",
    "        return 'Supervised'\n",
    "    elif 'Only Pretrained' in row:\n",
    "        return 'Zero-Shot\\nRandom Mask'\n",
    "    elif 'Random' in row:\n",
    "        return 'Random'\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "df_new_run['Unnamed: 0'] = df_new_run['Unnamed: 0'].apply(rename_model)\n",
    "\n",
    "model_colors = [color_baseline, color_zeroshot, color_supervised, color_ssl]\n",
    "\n",
    "# Step 3: Calculate mean and std for each model\n",
    "mean_std_df = df_new_run.groupby('Unnamed: 0')['f1-score: macro avg', 'f1-score: accuracy'].agg(['mean', 'std'])\n",
    "\n",
    "# Step 4: Create box plots\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties\n",
    "font = {'family': 'sans-serif', 'size': 5}  # This will be for titles and labels\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(3,2))\n",
    "ax = sns.boxplot(x='Unnamed: 0', y='f1-score: accuracy', data=df_new_run.sort_values('f1-score: accuracy'), linewidth=0.5, palette=model_colors)\n",
    "ax.set_xlabel('Model', fontdict=font)\n",
    "ax.set_ylabel('Micro F1 Score', fontdict=font)\n",
    "ax.set_title('Tabula Sapiens Classification Performance', fontdict=font)\n",
    "\n",
    "# Set font for all tick labels to match the fontdict\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font)\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Tabula_Sapiens_Clf_Micro_F1.svg\", bbox_inches='tight')  # Save as SVG\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Repeat for the second plot\n",
    "plt.figure(figsize=(3, 2))\n",
    "ax = sns.boxplot(x='Unnamed: 0', y='f1-score: macro avg', data=df_new_run.sort_values('f1-score: macro avg'), linewidth=0.5, palette=model_colors)\n",
    "ax.set_xlabel('Model', fontdict=font)\n",
    "ax.set_ylabel('Macro F1 Score', fontdict=font)\n",
    "ax.set_title('Tabula Sapiens Classification Performance', fontdict=font)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font)\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Tabula_Sapiens_Clf_Macro_F1.svg\", bbox_inches='tight')  # Save as SVG\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad39b0-14a7-466a-9f8c-cf34b53ee315",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae4d30c-d4cb-4179-b52c-aa1be49d90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = os.path.join(RESULTS_FOLDER, 'classification', 'val_clf_per_class_report_tabula_sapiens_merged_knn.csv')\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Show the first few rows to get an overview of the data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9bfa09-5aa2-4d87-8a7e-bfce0484c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between F1 scores of Self-Supervised and Supervised\n",
    "df['F1_Difference'] = df['F1_Self-Supervised'] - df['F1_Supervised']\n",
    "\n",
    "# Filter the data for positive, negative, and equal non-zero F1_Difference\n",
    "positive_diff = df[df['F1_Difference'] > 0]\n",
    "negative_diff = df[df['F1_Difference'] < 0]\n",
    "equal_non_zero_diff = df[(df['F1_Difference'] == 0)] # & (df['F1_Self-Supervised'] != 0) & (df['F1_Supervised'] != 0)]\n",
    "\n",
    "# Create a JointGrid without the right histogram (deactivate marginal plots)\n",
    "g = sns.JointGrid(x='Cell Count', y='F1_Difference', data=df, height=2.5, marginal_ticks=True, space=0.2)\n",
    "\n",
    "# Plot the scatter points with color depending on the sign of the F1_Difference\n",
    "# Points where Self-Supervised is better (positive difference)\n",
    "g.ax_joint.scatter(positive_diff['Cell Count'], positive_diff['F1_Difference'], \n",
    "                   s=5, color=color_ssl, label=\"Self-Supervised Better\")\n",
    "\n",
    "# Points where Supervised is better (negative difference)\n",
    "g.ax_joint.scatter(negative_diff['Cell Count'], negative_diff['F1_Difference'], \n",
    "                   s=5, color=color_supervised, label=\"Supervised Better\")\n",
    "\n",
    "# Points where performance is equal and non-zero\n",
    "g.ax_joint.scatter(equal_non_zero_diff['Cell Count'], equal_non_zero_diff['F1_Difference'], \n",
    "                   s=5, color=color_else2, label=\"Equal Performance (F1=0)\")\n",
    "\n",
    "# Histogram on the top\n",
    "g.ax_marg_x.hist(df['Cell Count'], bins=np.geomspace(df['Cell Count'].min(), df['Cell Count'].max(), 20), \n",
    "                 alpha=.6, edgecolor='black', color='grey')\n",
    "\n",
    "# Labels & Title\n",
    "g.set_axis_labels('Number of Cells per Cell Type (log scale)', 'Performance Difference (Δ Macro F1)', **font)\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "# Adjust legend with font properties\n",
    "g.ax_joint.legend(prop=font)\n",
    "\n",
    "# Apply font properties to all tick labels\n",
    "for label in g.ax_joint.get_xticklabels() + g.ax_joint.get_yticklabels():\n",
    "    label.set_fontsize(font['size'])\n",
    "    label.set_family(font['family'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Tabula_Sapiens_Per_CT_Difference.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcf4d8-fcfb-4d87-adb4-ea39f7503a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a colorblind-friendly palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "colors = sns.color_palette()\n",
    "\n",
    "# Define font properties\n",
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust the size as needed\n",
    "\n",
    "# Create a JointGrid with specified height\n",
    "g = sns.JointGrid(x='Cell Count', y='F1_Supervised', data=df, height=3, marginal_ticks=True, space=0.2)\n",
    "g = g.plot_joint(plt.scatter, s=6, color=colors[0], label=\"Supervised\")  # Model A in one color\n",
    "g.ax_joint.scatter(df['Cell Count'], df['F1_Self-Supervised'], s=6, color=colors[1], label=\"Self Supervised\")  # Model B in another color\n",
    "\n",
    "# Histograms\n",
    "g.ax_marg_x.hist(df['Cell Count'], bins=np.geomspace(df['Cell Count'].min(), df['Cell Count'].max(), 20), alpha=.6, edgecolor='black', color=colors[2])\n",
    "g.ax_marg_y.hist(df['F1_Supervised'], bins=np.linspace(0, 1, 20), alpha=.6, orientation='horizontal', edgecolor='black', color=colors[0])\n",
    "g.ax_marg_y.hist(df['F1_Self-Supervised'], bins=np.linspace(0, 1, 20), alpha=.6, orientation='horizontal', edgecolor='black', color=colors[1])\n",
    "\n",
    "# Labels & Title\n",
    "g.set_axis_labels('Number of Cells per Cell Type (log scale)', 'F1-Score per Cell Type', **font)\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "# Adjust legend with font properties\n",
    "g.ax_joint.legend(prop=font)\n",
    "\n",
    "# Apply font properties to all tick labels\n",
    "for ax in [g.ax_joint, g.ax_marg_x, g.ax_marg_y]:\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        label.set_fontsize(font['size'])\n",
    "        label.set_family(font['family'])\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/Tabula_Sapiens_per_celltype_perf.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d9e59-5d7c-4a66-baf8-03cd6aeff659",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51a2de-644e-466a-b70c-d6cc1e9343b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_supervised = np.load(os.path.join(RESULTS_FOLDER, 'classification', 'new_predicted_labels_No_SSL_new_run4_Tabula_Sapiens_No SSL.npy'))\n",
    "y_pred_ssl = np.load(os.path.join(RESULTS_FOLDER, 'classification', 'new_predicted_labels_SSL_CN_MLP_50pnew_run0_Tabula_Sapiens_SSL.npy'))\n",
    "y_true = np.load(os.path.join(RESULTS_FOLDER, 'classification', 'new_true_labels_No_SSL_new_run4_Tabula_Sapiens_No SSL.npy'))  # same as for ssl, deterministic data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda88f0c-c9e8-48f2-9933-7054edf23166",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_ssl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc41b90-de47-4754-a3e8-2016e87643db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correct predictions\n",
    "correct_supervised = np.equal(y_pred_supervised, y_true).astype(int)\n",
    "correct_ssl = np.equal(y_pred_ssl, y_true).astype(int)\n",
    "\n",
    "# Calculate the sum of correct predictions for each class\n",
    "unique_classes = np.unique(y_true)\n",
    "correct_counts_supervised = [np.sum(correct_supervised[y_true == cls]) for cls in unique_classes]\n",
    "correct_counts_ssl = [np.sum(correct_ssl[y_true == cls]) for cls in unique_classes]\n",
    "\n",
    "# Calculate the differences\n",
    "differences = np.array(correct_counts_ssl) - np.array(correct_counts_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f45bb-20ae-42a2-ab1d-b693be4cb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_mapping = pd.read_parquet(\n",
    "        os.path.join(STORE_DIR, \"categorical_lookup/cell_type.parquet\")\n",
    "    )\n",
    "cell_type_mapping['label'] = cell_type_mapping['label'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a4815-6f10-42a9-a60e-dbc5f81df22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_true == 160).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715661ac-2a63-4112-85e5-735d9c7ed0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pneumocyte_supervised = [np.sum(correct_supervised[y_true == cls]) for cls in [160]]\n",
    "correct_pneumocyte_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83287915-cd1a-43aa-8786-5d60ec6a3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pneumocyte_ssl = [np.sum(correct_ssl[y_true == cls]) for cls in [160]]\n",
    "correct_pneumocyte_ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479d0b3-bd4e-4f21-9a35-b7d65aa62752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for plotting\n",
    "df_plot = pd.DataFrame({\n",
    "    'Class': unique_classes,\n",
    "    'Difference': differences\n",
    "})\n",
    "\n",
    "# Sort by absolute difference and select top n classes\n",
    "n = 6  # Replace with your desired number of classes\n",
    "df_plot['Absolute Difference'] = df_plot['Difference'].abs()\n",
    "df_top_n = df_plot.sort_values(by='Absolute Difference', ascending=False).head(n)\n",
    "\n",
    "# Assign colors based on the sign of the difference\n",
    "df_top_n['Color'] = df_top_n['Difference'].apply(lambda x: color_ssl if x > 0 else color_supervised)\n",
    "\n",
    "# Create a mapping dictionary from integer labels to string names\n",
    "label_to_name_dict = cell_type_mapping['label'].to_dict()\n",
    "\n",
    "# Replace integer class labels in df_top_n with string names\n",
    "df_top_n['Class'] = df_top_n['Class'].map(label_to_name_dict)\n",
    "\n",
    "# Plotting\n",
    "bar_colors = [color_ssl, color_ssl, color_ssl, color_supervised, color_supervised, color_supervised]\n",
    "\n",
    "plt.figure(figsize=(2.5, 2.5))\n",
    "ax = sns.barplot(x='Class', y='Difference', data=df_top_n, palette=bar_colors)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, **tick_font, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=45, **tick_font, ha='right')\n",
    "ax.set_xlabel('Class', fontdict=font)\n",
    "ax.set_ylabel('Δ Correct Predictions', fontdict=font)\n",
    "ax.set_title('Tabula Sapiens Cell Type Prediction Difference', fontdict=font)\n",
    "\n",
    "# Annotate bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=font['size'])\n",
    "# Create legend handles\n",
    "ssl_patch = mpatches.Patch(color=color_ssl, label='Self-Supervised Better')\n",
    "supervised_patch = mpatches.Patch(color=color_supervised, label='Supervised Better')\n",
    "\n",
    "# Add legend to the plot\n",
    "ax.legend(handles=[ssl_patch, supervised_patch], loc='upper right', prop=font)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/tabula_sapiens_biggest_difference_barplot.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70f450-0647-4a76-bc07-22a1b71b0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_counts_supervised = pd.read_csv(os.path.join(RESULTS_FOLDER, 'classification', 'correct_counts_No_SSL_new_run4_Tabula_Sapiens_No SSL.csv'), index_col='Unnamed: 0')\n",
    "true_counts_ssl = pd.read_csv(os.path.join(RESULTS_FOLDER, 'classification', 'correct_counts_SSL_CN_MLP_50pnew_run0_Tabula_Sapiens_SSL.csv'), index_col='Unnamed: 0')\n",
    "true_counts = pd.read_csv(os.path.join(RESULTS_FOLDER, 'classification', 'Tabula_Sapiens_true_counts.csv'), index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691cdaca-80c2-4488-ae88-acea71704a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure cell type names are capitalized\n",
    "true_counts_ssl['Cell Type'] = true_counts_ssl.index.str.title()\n",
    "true_counts_supervised['Cell Type'] = true_counts_supervised.index.str.title()\n",
    "\n",
    "# Merge the dataframes on cell type\n",
    "df_merged = pd.merge(true_counts_ssl, true_counts_supervised, on='Cell Type', suffixes=('_self', '_supervised'))\n",
    "\n",
    "# Calculate the difference in counts\n",
    "df_merged['Count Difference'] = df_merged['Correct Count_self'] - df_merged['Correct Count_supervised']\n",
    "\n",
    "# Select n cell types with the largest absolute differences\n",
    "n = 6 # You can adjust this number\n",
    "df_subset = df_merged.reindex(df_merged['Count Difference'].abs().nlargest(n).index)\n",
    "\n",
    "# Assign colors based on whether the self-supervised model is better or not\n",
    "df_subset['Color'] = df_subset['Count Difference'].apply(lambda x: color_ssl if x > 0 else color_supervised)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(4, 3))\n",
    "ax = sns.barplot(x='Cell Type', y='Count Difference', data=df_subset, palette=df_subset['Color'].tolist())\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, **tick_font, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=45, **tick_font, ha='right')\n",
    "ax.set_xlabel('Cell Type', fontdict=font)\n",
    "ax.set_ylabel('Count Difference', fontdict=font)\n",
    "ax.set_title('Tabula Sapiens Cell Type Prediction Difference', fontdict=font)\n",
    "\n",
    "# Annotate bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=font['size'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c391d8b4-f635-459d-8563-b549daf2a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_supervised = pd.read_csv(os.path.join(RESULTS_FOLDER, 'classification', 'conf_matrix_No_SSL_new_run4_Tabula_Sapiens_No SSL.csv'), index_col='Unnamed: 0')\n",
    "conf_matrix_ssl = pd.read_csv(os.path.join(RESULTS_FOLDER, 'classification', 'conf_matrix_SSL_CN_MLP_50pnew_run0_Tabula_Sapiens_SSL.csv'), index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f05019-4af3-4cdd-a568-e91994501ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing up the columns for each confusion matrix\n",
    "sum_per_class_1 = conf_matrix_supervised.sum(axis=0)\n",
    "sum_per_class_2 = conf_matrix_ssl.sum(axis=0)\n",
    "\n",
    "# Display the sums\n",
    "print(\"Sum per class for the first model:\\n\", sum_per_class_1)\n",
    "print(\"\\nSum per class for the second model:\\n\", sum_per_class_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd63947-fa0c-449c-bb7d-812db80405d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference matrix\n",
    "conf_matrix_difference = conf_matrix_ssl - conf_matrix_supervised\n",
    "\n",
    "# Identify the top N cell types with the largest absolute differences\n",
    "N = 5  # Number of top differences to display\n",
    "top_differences = conf_matrix_difference.abs().sum(axis=1).nlargest(N).index\n",
    "\n",
    "# Create a subset DataFrame for these top differences\n",
    "conf_matrix_subset = conf_matrix_difference.loc[top_differences, top_differences]\n",
    "\n",
    "# Capitalize the first letter of each word in the columns\n",
    "conf_matrix_subset.columns = conf_matrix_subset.columns.str.title()\n",
    "\n",
    "# Capitalize the first letter of each word in the index\n",
    "conf_matrix_subset.index = conf_matrix_subset.index.str.title()\n",
    "\n",
    "# Create a custom diverging colormap\n",
    "top = mcolors.to_rgba(color_ssl)\n",
    "bottom = mcolors.to_rgba(color_supervised)\n",
    "custom_colormap = mcolors.LinearSegmentedColormap.from_list(\"custom_map\", [bottom, \"white\", top])\n",
    "\n",
    "# Define the range for the colormap\n",
    "max_abs_value = np.abs(conf_matrix_subset.values).max()\n",
    "vmin, vmax = -max_abs_value, max_abs_value\n",
    "\n",
    "# Create heatmap without annotations for the subset difference matrix\n",
    "plt.figure(figsize=(1.5, 1.2))  # Adjust figure size as needed for better visibility\n",
    "ax = sns.heatmap(conf_matrix_subset, annot=False, cmap=custom_colormap, linewidths=.5, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(conf_matrix_subset.columns, **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(conf_matrix_subset.index, **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('Tabula Sapiens Performance Difference', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/tabula_sapiens_biggest_difference_confusion_matrix.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6427ff-325c-4517-8c98-692afef7f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference matrix\n",
    "conf_matrix_difference = conf_matrix_ssl - conf_matrix_supervised\n",
    "\n",
    "# Create a custom diverging colormap\n",
    "top = mcolors.to_rgba(color_ssl)\n",
    "bottom = mcolors.to_rgba(color_supervised)\n",
    "custom_colormap = mcolors.LinearSegmentedColormap.from_list(\"custom_map\", [bottom, \"white\", top])\n",
    "\n",
    "# Create heatmap without annotations for the difference matrix\n",
    "plt.figure(figsize=(10, 8))  # Adjust figure size as needed for better visibility\n",
    "ax = sns.heatmap(conf_matrix_difference, annot=False, cmap=custom_colormap, linewidths=.5)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(conf_matrix_difference.columns, **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(conf_matrix_difference.index, **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('Tabula Sapiens Performance Difference: Self-Supervised vs Supervised Model\\n(Positive: More Counts Self-Supervised, Negative: More Counts Supervised)', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/tabula_sapiens_difference_confusion_matrix.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec85b3-f0ed-4dea-8254-c16ca0cab011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for the plots\n",
    "sns.set_theme()\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties for titles and labels\n",
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust size as needed\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}  # Adjust font size for tick labels\n",
    "\n",
    "# Create heatmap without annotations\n",
    "plt.figure(figsize=(5, 4))  # Adjust figure size as needed\n",
    "ax = sns.heatmap(conf_matrix_supervised, annot=False, cmap='viridis', linewidths=.5)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('Tabula Sapiens Confusion Matrix Supervised Model', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/confusion_matrix_tabula_sapiens_supervised.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a872639-1a92-4ac2-85de-9a31e85fbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for the plots\n",
    "sns.set_theme()\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Define font properties for titles and labels\n",
    "font = {'family': 'sans-serif', 'size': 5}  # Adjust size as needed\n",
    "tick_font = {'fontsize': 5, 'fontname': 'sans-serif'}  # Adjust font size for tick labels\n",
    "\n",
    "# Create heatmap without annotations\n",
    "plt.figure(figsize=(5, 4))  # Adjust figure size as needed\n",
    "ax = sns.heatmap(conf_matrix_ssl, annot=False, cmap='viridis', linewidths=.5)\n",
    "\n",
    "# Set the font for the tick labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), **tick_font, rotation=45, ha='right')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), **tick_font, rotation=0)\n",
    "\n",
    "# Set the font for the axis labels and title\n",
    "ax.set_xlabel('Predicted Label', fontdict=font)\n",
    "ax.set_ylabel('True Label', fontdict=font)\n",
    "ax.set_title('Tabula Sapiens Confusion Matrix Self-Supervised Model', fontdict=font)\n",
    "\n",
    "# Adjust the font for the numbers on the heatbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust font size for color bar\n",
    "\n",
    "# Change font for the color bar tick labels\n",
    "for label in cbar.ax.get_yticklabels():\n",
    "    label.set_fontname('sans-serif')\n",
    "    label.set_fontsize(5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_FOLDER + \"/classification/confusion_matrix_tabula_sapiens_ssl.svg\", bbox_inches='tight')  # Save as SVG\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:celldreamer]",
   "language": "python",
   "name": "celldreamer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
