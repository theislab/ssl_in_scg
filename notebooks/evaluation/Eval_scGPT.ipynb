{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1982772-afa0-4426-9960-fc2b583b2d3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Zero-Shot Evaluation of scGPT\n",
    "Following https://scgpt.readthedocs.io/en/latest/tutorial_annotation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56833f9e-2037-4b54-bc1e-b8de28495981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1185082-5d2c-4750-829c-fff29bab4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/lustre/groups/ml01/workspace/till.richter/merlin_cxg_2023_05_15_sf-log1p\"\n",
    "SAVE_PATH = \"/lustre/groups/ml01/workspace/till.richter/trained_models/final_models/classification/scGPT\"\n",
    "ADATA_PATH = join(DATA_PATH, 'adata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19e892d-7a44-419a-94f5-02cb97db6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_matrix(ddf):\n",
    "    x = (\n",
    "        ddf['X']\n",
    "        .map_partitions(\n",
    "            lambda xx: pd.DataFrame(np.vstack(xx.tolist())), \n",
    "            meta={col: 'f4' for col in range(19331)}\n",
    "        )\n",
    "        .to_dask_array(lengths=[1024] * ddf.npartitions)\n",
    "    )\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86231bf1-907d-43e5-81ea-729cccc3109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells_train = 1_500_000\n",
    "\n",
    "ddf_train = dd.read_parquet(join(DATA_PATH, 'train'), split_row_groups=True)\n",
    "x_train = get_count_matrix(ddf_train)[:n_cells_train, :]\n",
    "y_train = dd.read_parquet(join(DATA_PATH, 'train'), columns=['cell_type']).compute().iloc[:n_cells_train]\n",
    "\n",
    "ddf_test = dd.read_parquet(join(DATA_PATH, 'test'), split_row_groups=True)\n",
    "x_test = get_count_matrix(ddf_test)\n",
    "y_test = dd.read_parquet(join(DATA_PATH, 'test'), columns=['cell_type']).compute()\n",
    "\n",
    "var = pd.read_parquet(join(DATA_PATH, 'var.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb741bd-9d4e-46b7-a116-fc7e3e49297c",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b2f24f-9f66-458a-a4c4-e0c0efac50e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d484a50a0041749f41d5f095bbdb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run inference in batches to save memory\n",
    "\n",
    "for i, idxs in tqdm(enumerate(np.array_split(np.arange(x_train.shape[0]), 10))):\n",
    "    # data is already normalized\n",
    "    anndata.AnnData(\n",
    "        X=x_train[idxs, :].map_blocks(csr_matrix).compute(), \n",
    "        var=var.set_index('feature_name'),\n",
    "        obs=y_train.iloc[idxs]\n",
    "    ).write_h5ad(join(ADATA_PATH, 'adata_train', f'{i}.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed716594-1f78-4595-8490-51cde6833e20",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af816574-1a02-4e29-b522-d52f5ef44b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ffe340528048969d8929915d845554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, idxs in tqdm(enumerate(np.array_split(np.arange(x_test.shape[0]), 30))):\n",
    "    # data is already normalized\n",
    "    anndata.AnnData(\n",
    "        X=x_test[idxs, :].map_blocks(csr_matrix).compute(), \n",
    "        var=var.set_index('feature_name'),\n",
    "        obs=y_test.iloc[idxs]\n",
    "    ).write_h5ad(join(ADATA_PATH, 'adata_test', f'{i}.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f5f3fc-1ab9-448e-a873-c2f58a7ee314",
   "metadata": {},
   "source": [
    "### Get embeddings from scGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e2ca1-12b3-43c8-99ab-83c03b8ac67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os.path import join\n",
    "\n",
    "import scgpt as scg\n",
    "import anndata\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d105c1-e0d5-45f5-af04-b0df830253c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(SAVE_PATH)\n",
    "cell_type_key = \"cell_type\"\n",
    "gene_col = \"index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e8921-993a-4b3b-8f99-8b94da9358db",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a87bb-e98a-45b2-9f5e-4e9413eca47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    adata = sc.read_h5ad(join(SAVE_PATH, 'train', f'{i}.h5ad'))\n",
    "    adata = scg.tasks.embed_data(\n",
    "        adata,\n",
    "        model_dir,\n",
    "        cell_type_key=cell_type_key,\n",
    "        gene_col=gene_col,\n",
    "        batch_size=64,\n",
    "        return_new_adata=True,\n",
    "    ).write_h5ad(join(SAVE_PATH, 'train', f'{i}_embed.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ce842-827c-4b76-ab11-c70ab1a7dfcc",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880a585-e0b6-4596-aac6-1a53e0ba819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    adata = sc.read_h5ad(join(SAVE_PATH, 'test', f'{i}.h5ad'))\n",
    "    adata = scg.tasks.embed_data(\n",
    "        adata,\n",
    "        model_dir,\n",
    "        cell_type_key=cell_type_key,\n",
    "        gene_col=gene_col,\n",
    "        batch_size=64,\n",
    "        return_new_adata=True,\n",
    "    ).write_h5ad(join(SAVE_PATH, 'test', f'{i}_embed.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb1445-0a25-411d-9fb9-63c32e572ac8",
   "metadata": {},
   "source": [
    "# Evaluate scGPT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15243ac2-bcab-4b87-9ced-b1b6814a8547",
   "metadata": {},
   "source": [
    "### Train Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5483f-1588-4215-9666-5c2f3d598967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "\n",
    "from cuml.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1955d-f343-41db-add9-76c32237b9d3",
   "metadata": {},
   "source": [
    "### Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64e585-be8d-480a-8006-37c490e5403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from statistics import mean, stdev\n",
    "\n",
    "from utils import correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3269d-2866-456e-a825-70cf9b88eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_mapping = pd.read_parquet(join(DATA_PATH, 'categorical_lookup/cell_type.parquet'))\n",
    "cell_type_hierarchy = np.load(join(DATA_PATH, 'cell_type_hierarchy/child_matrix.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643eef9c-41b3-4ff5-95c3-0d87a86d2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scgpt as scg\n",
    "import anndata\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "cell_type_key = \"cell_type\"\n",
    "gene_col = \"index\"\n",
    "\n",
    "# Process test data to generate embeddings\n",
    "for i in range(30):  # Assuming you have 30 test splits as in the original code\n",
    "    # Load the h5ad file\n",
    "    adata = sc.read_h5ad(join(SAVE_PATH, 'test', f'{i}.h5ad'))\n",
    "    \n",
    "    # Generate embeddings using the scGPT model\n",
    "    embeddings = scg.tasks.embed_data(\n",
    "        adata,\n",
    "        model_dir,\n",
    "        cell_type_key=cell_type_key,\n",
    "        gene_col=gene_col,\n",
    "        batch_size=64,\n",
    "        return_new_adata=True,\n",
    "    ).X  # Extract the X (embedding) part of the Anndata object\n",
    "    \n",
    "    # Save the embeddings as a .npy file\n",
    "    np.save(join(SAVE_PATH, 'test', f'{i}_embed.npy'), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6ff0c-7420-48d4-9931-2baf1672229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_reports = []\n",
    "\n",
    "for clf in clf_list:\n",
    "    preds = clf.predict(X_test)\n",
    "    preds_corr = correct_labels(y_test, preds, cell_type_hierarchy)\n",
    "    clf_reports.append(pd.DataFrame(classification_report(y_test, preds_corr, output_dict=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41eae8-8467-4fb7-9ff1-c721151bf118",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_scgpt = [clf_report.loc['macro avg', 'f1-score'] for clf_report in clf_reports]\n",
    "print(f'{mean(f1_scores_scgpt):.4f}±{stdev(f1_scores_scgpt):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b08c0e-323f-4c68-a820-9944aa47cd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa67d17b-768a-43c7-9e0a-835fb29f5295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db09c85-8880-4f57-b352-457f4e8b1ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adbf22-f08e-4b86-8c5e-1d201beedfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c406eb-9bac-44c1-8cdb-17bc4c1c7563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d25cb9f6-7970-4157-a630-a273607dcb0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/lustre/groups/ml01/workspace/till.richter/trained_models/scGPT/best_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_path = \"/lustre/groups/ml01/workspace/till.richter/trained_models/scGPT/best_model.pt\"\n",
    "model = torch.load(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72157c2f-1ac5-4a69-8f29-6169cbc6b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract embeddings\n",
    "def get_embeddings(dataloader, model):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch in dataloader:\n",
    "        # Obtain the input tensor from the batch. Adjust this line according to your dataloader's structure.\n",
    "        inputs = batch['input_ids']\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=inputs)\n",
    "        \n",
    "        # Assuming the output of your model provides the embeddings directly. If not, adjust accordingly.\n",
    "        embeddings.append(output.embeddings)\n",
    "        labels.append(batch['labels'])\n",
    "    \n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = torch.cat(labels)\n",
    "    return embeddings, labels\n",
    "\n",
    "# Get embeddings and labels from the validation set\n",
    "val_embeddings, val_labels = get_embeddings(estim.datamodule.val_dataloader(), model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:celldreamer]",
   "language": "python",
   "name": "celldreamer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
