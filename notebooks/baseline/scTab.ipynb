{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ffe3305-a78c-4adc-a2ab-1ab8a560a033",
   "metadata": {},
   "source": [
    "Model Inference With scTab\n",
    "\n",
    "From https://github.com/theislab/scTab/blob/devel/notebooks-tutorials/model_inference.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1cf95e-1958-40bf-b23b-b475664be1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import anndata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scanpy as sc\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "import yaml\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a3a24-26f4-4046-9346-7b185b99b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellnet.utils.data_loading import dataloader_factory, streamline_count_matrix\n",
    "from cellnet.tabnet.tab_network import TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede063d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_supervision.paths import DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2e83b-6b9f-40c4-918b-3cdde27baa55",
   "metadata": {},
   "source": [
    "## 1. Load data set\n",
    "\n",
    "In Tutorial the example dataset\n",
    "\n",
    "Here we load the HLCA, TabulaSapiens, and PBMC atlases used in the SSL study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e970ec-4c4b-4ffe-a0e8-49484af162ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c252a-39f4-4e9c-a4ba-ce864fc00636",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_hlca = anndata.read_h5ad(ckpt_dir + 'cellxgene_test_dataset_HLCA_adata.h5ad')\n",
    "adata_pbmc = anndata.read_h5ad(ckpt_dir + 'cellxgene_test_dataset_PBMC_adata.h5ad')\n",
    "adata_tabula_sapiens = anndata.read_h5ad(ckpt_dir + 'cellxgene_test_dataset_TabulaSapiens_adata.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eae185-0a63-4a85-87c7-15e9749d5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hlca = adata_hlca.X\n",
    "x_pbmc = adata_pbmc.X\n",
    "x_tabula_sapiens = adata_tabula_sapiens.X\n",
    "\n",
    "y_hlca = adata_hlca.obs['cell_type']\n",
    "y_pbmc = adata_pbmc.obs['cell_type']\n",
    "y_tabula_sapiens = adata_tabula_sapiens.obs['cell_type']\n",
    "\n",
    "print('HLCA: ', x_hlca.shape[0], ' cells', len(y_hlca), 'classes')\n",
    "print('PBMC: ', x_pbmc.shape[0], ' cells', len(y_pbmc), 'classes')\n",
    "print('Tabula Sapiens: ', x_tabula_sapiens.shape[0], ' cells', len(y_tabula_sapiens), 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d2541-6201-42e2-991a-2eae83256a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap dataset into pytorch data loader to use for batched inference\n",
    "hlca_loader = dataloader_factory(x_hlca, batch_size=2048)\n",
    "pbmc_loader = dataloader_factory(x_pbmc, batch_size=2048)\n",
    "tabula_sapiens_loader = dataloader_factory(x_tabula_sapiens, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575ffcc-5f5a-4a83-9ce0-48f6a92da336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_labels(y_true: np.ndarray, y_pred: np.ndarray, child_matrix: np.ndarray):\n",
    "    \"\"\"\n",
    "    Update predictions.\n",
    "    If prediction is actually a child node of the true label -> update prediction to true value.\n",
    "\n",
    "    E.g: Label='T cell' and prediction='CD8 positive T cell' -> update prediction to 'T cell'\n",
    "    \"\"\"\n",
    "    updated_predictions = y_pred.copy()\n",
    "    # precalculate child nodes\n",
    "    child_nodes = {i: np.where(child_matrix[i, :])[0] for i in range(child_matrix.shape[0])}\n",
    "\n",
    "    for i, (pred, true_label) in enumerate(zip(y_pred, y_true)):\n",
    "        if pred in child_nodes[true_label]:\n",
    "            updated_predictions[i] = true_label\n",
    "        else:\n",
    "            updated_predictions[i] = pred\n",
    "\n",
    "    return updated_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01321c2e-4c3e-4426-9da3-e06397b250e4",
   "metadata": {},
   "source": [
    "## 2. Load weights from checkpoint and intialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ef82d-ff24-49fb-9725-442f5937cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint\n",
    "if torch.cuda.is_available():\n",
    "    ckpt = torch.load(\n",
    "        ckpt_dir + 'scTab-checkpoints/scTab/run5/val_f1_macro_epoch=41_val_f1_macro=0.847.ckpt', \n",
    "    )\n",
    "else:\n",
    "    # map to cpu if there is not gpu available\n",
    "    ckpt = torch.load(\n",
    "        ckpt_dir + 'scTab-checkpoints/scTab/run5/val_f1_macro_epoch=41_val_f1_macro=0.847.ckpt', \n",
    "        map_location=torch.device('cpu')\n",
    "    )\n",
    "\n",
    "# extract state_dict of tabnet model from checkpoint\n",
    "# I can do this as well and just send you the updated checkpoint file - I think this would be the best solution\n",
    "# I just put this here for completeness\n",
    "tabnet_weights = OrderedDict()\n",
    "for name, weight in ckpt['state_dict'].items():\n",
    "    if 'classifier.' in name:\n",
    "        tabnet_weights[name.replace('classifier.', '')] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c6017-f7d7-4421-bca1-f997c30409a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load in hparams file of model to get model architecture\n",
    "with open(ckpt_dir + 'scTab-checkpoints/scTab/run5/hparams.yaml') as f:\n",
    "    model_params = yaml.full_load(f.read())\n",
    "\n",
    "\n",
    "# initialzie model with hparams from hparams.yaml file\n",
    "tabnet = TabNet(\n",
    "    input_dim=model_params['gene_dim'],\n",
    "    output_dim=model_params['type_dim'],\n",
    "    n_d=model_params['n_d'],\n",
    "    n_a=model_params['n_a'],\n",
    "    n_steps=model_params['n_steps'],\n",
    "    gamma=model_params['gamma'],\n",
    "    n_independent=model_params['n_independent'],\n",
    "    n_shared=model_params['n_shared'],\n",
    "    epsilon=model_params['epsilon'],\n",
    "    virtual_batch_size=model_params['virtual_batch_size'],\n",
    "    momentum=model_params['momentum'],\n",
    "    mask_type=model_params['mask_type'],\n",
    ")\n",
    "\n",
    "# load trained weights\n",
    "tabnet.load_state_dict(tabnet_weights)\n",
    "# set model to inference mode\n",
    "tabnet.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4058cf14-a4d3-496c-a33f-ced0c148dd0a",
   "metadata": {},
   "source": [
    "## 3. Run model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc27034-24b4-4437-86eb-6a84745b828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_hlca = []\n",
    "preds_pbmc = []\n",
    "preds_tabula_sapiens = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(hlca_loader):\n",
    "        # normalize data\n",
    "        x_input = batch[0]['X']\n",
    "        logits, _ = tabnet(x_input)\n",
    "        preds_hlca.append(torch.argmax(logits, dim=1).numpy())\n",
    "\n",
    "    for batch in tqdm(pbmc_loader):\n",
    "        # normalize data\n",
    "        x_input = batch[0]['X']\n",
    "        logits, _ = tabnet(x_input)\n",
    "        preds_pbmc.append(torch.argmax(logits, dim=1).numpy())\n",
    "\n",
    "    for batch in tqdm(tabula_sapiens_loader):\n",
    "        # normalize data\n",
    "        x_input = batch[0]['X']\n",
    "        logits, _ = tabnet(x_input)\n",
    "        preds_tabula_sapiens.append(torch.argmax(logits, dim=1).numpy())\n",
    "        \n",
    "\n",
    "\n",
    "preds_hlca = np.hstack(preds_hlca)\n",
    "preds_pbmc = np.hstack(preds_pbmc)\n",
    "preds_tabula_sapiens = np.hstack(preds_tabula_sapiens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de408c80-0219-40f5-8b2a-3d18f05b37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model outputs just integers -> each int corresponds to a specific cell type\n",
    "# revert this mapping \n",
    "base_path = os.path.join(DATA_DIR, 'merlin_cxg_2023_05_15_sf-log1p')\n",
    "sctab_path = os.path.join(DATA_DIR, 'merlin_cxg_2023_05_15_sf-log1p_minimal')\n",
    "cell_type_mapping_ssl = pd.read_parquet(base_path + '/categorical_lookup/cell_type.parquet')\n",
    "cell_type_mapping_sctab = pd.read_parquet(sctab_path + '/categorical_lookup/cell_type.parquet')\n",
    "cell_type_hierarchy = np.load(base_path + '/cell_type_hierarchy/child_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af917312-8b24-4e08-b796-bb8149020db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_corr_hlca = correct_labels(y_hlca, preds_hlca, cell_type_hierarchy)\n",
    "y_pred_corr_pbmc = correct_labels(y_pbmc, preds_pbmc, cell_type_hierarchy)\n",
    "y_pred_corr_tabula_sapiens = correct_labels(y_tabula_sapiens, preds_tabula_sapiens, cell_type_hierarchy)\n",
    "\n",
    "true_hlca = cell_type_mapping_sctab.loc[y_hlca]['label'].to_numpy()\n",
    "true_pbmc = cell_type_mapping_sctab.loc[y_pbmc]['label'].to_numpy()\n",
    "true_tabula_sapiens = cell_type_mapping_sctab.loc[y_tabula_sapiens]['label'].to_numpy()\n",
    "\n",
    "y_pred_corr_hlca_str = cell_type_mapping_ssl.loc[y_pred_corr_hlca]['label'].to_numpy()\n",
    "y_pred_corr_pbmc_str = cell_type_mapping_ssl.loc[y_pred_corr_pbmc]['label'].to_numpy()\n",
    "y_pred_corr_tabula_sapiens_str = cell_type_mapping_ssl.loc[y_pred_corr_tabula_sapiens]['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c73f5-fc13-4b11-9ff2-e081b101ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "clf_report = pd.DataFrame(classification_report(\n",
    "    true_hlca,\n",
    "    y_pred_corr_hlca,\n",
    "    labels=np.unique(true_hlca),\n",
    "    output_dict=True\n",
    ")).T\n",
    "clf_report_overall = clf_report.iloc[-3].copy()\n",
    "clf_report_per_class = clf_report.iloc[:-3].copy()\n",
    "clf_report_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99998ade-5325-4417-9c5b-4cf05aba3708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# HLCA\n",
    "micro_f1_hlca = f1_score(y_hlca, preds_hlca, average='micro')\n",
    "macro_f1_hlca = f1_score(y_hlca, preds_hlca, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a034c10-0977-45d0-ba64-00e58ead54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_hlca = cell_type_mapping_ssl.loc[preds_hlca]['label'].to_numpy()\n",
    "preds_pbmc = cell_type_mapping_ssl.loc[preds_pbmc]['label'].to_numpy()\n",
    "preds_tabula_sapiens = cell_type_mapping_ssl.loc[preds_tabula_sapiens]['label'].to_numpy()\n",
    "\n",
    "preds_hlca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1156e-2450-4d49-a737-ab3633225dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_hlca = cell_type_mapping_sctab.loc[y_hlca]['label'].to_numpy()\n",
    "true_pbmc = cell_type_mapping_sctab.loc[y_pbmc]['label'].to_numpy()\n",
    "true_tabula_sapiens = cell_type_mapping_sctab.loc[y_tabula_sapiens]['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d5ef9-9711-4e5e-b740-3455fd071b7a",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcaa3cc-6781-42ff-896d-923fc4572470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# HLCA\n",
    "micro_f1_hlca = f1_score(true_hlca, y_pred_corr_hlca_str, average='micro', labels=np.unique(true_hlca))\n",
    "macro_f1_hlca = f1_score(true_hlca, y_pred_corr_hlca_str, average='macro', labels=np.unique(true_hlca))\n",
    "\n",
    "# PBMC\n",
    "micro_f1_pbmc = f1_score(true_pbmc, y_pred_corr_pbmc_str, average='micro', labels=np.unique(true_pbmc))\n",
    "macro_f1_pbmc = f1_score(true_pbmc, y_pred_corr_pbmc_str, average='macro', labels=np.unique(true_pbmc))\n",
    "\n",
    "# Tabula Sapiens\n",
    "micro_f1_tabula_sapiens = f1_score(true_tabula_sapiens, y_pred_corr_tabula_sapiens_str, average='micro', labels=np.unique(true_tabula_sapiens))\n",
    "macro_f1_tabula_sapiens = f1_score(true_tabula_sapiens, y_pred_corr_tabula_sapiens_str, average='macro', labels=np.unique(true_tabula_sapiens))\n",
    "\n",
    "# Print the results\n",
    "print(f'HLCA - Micro F1: {micro_f1_hlca}, Macro F1: {macro_f1_hlca}')\n",
    "print(f'PBMC - Micro F1: {micro_f1_pbmc}, Macro F1: {macro_f1_pbmc}')\n",
    "print(f'Tabula Sapiens - Micro F1: {micro_f1_tabula_sapiens}, Macro F1: {macro_f1_tabula_sapiens}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:celldreamer]",
   "language": "python",
   "name": "celldreamer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
